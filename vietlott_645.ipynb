{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2174711d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vietlott_env\\Scripts\\activate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38dee3a4",
   "metadata": {},
   "source": [
    "# Cài đặt thư viện "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ce83c95f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in e:\\python3_8_64bit\\lib\\site-packages (2.0.3)\n",
      "Requirement already satisfied: deap in e:\\python3_8_64bit\\lib\\site-packages (1.4.3)\n",
      "Requirement already satisfied: requests in e:\\python3_8_64bit\\lib\\site-packages (2.32.3)\n",
      "Requirement already satisfied: bayesian-optimization in e:\\python3_8_64bit\\lib\\site-packages (1.4.3)\n",
      "Requirement already satisfied: beautifulsoup4 in e:\\python3_8_64bit\\lib\\site-packages (4.13.4)\n",
      "Requirement already satisfied: seaborn in e:\\python3_8_64bit\\lib\\site-packages (0.13.2)\n",
      "Requirement already satisfied: selenium in e:\\python3_8_64bit\\lib\\site-packages (4.27.1)\n",
      "Requirement already satisfied: matplotlib in e:\\python3_8_64bit\\lib\\site-packages (3.7.5)\n",
      "Requirement already satisfied: sklearn in e:\\python3_8_64bit\\lib\\site-packages (0.0)\n",
      "Requirement already satisfied: tensorflow in e:\\python3_8_64bit\\lib\\site-packages (2.12.0)\n",
      "Requirement already satisfied: numpy in e:\\python3_8_64bit\\lib\\site-packages (1.23.5)\n",
      "Requirement already satisfied: scikit-learn in e:\\python3_8_64bit\\lib\\site-packages (1.3.2)\n",
      "Requirement already satisfied: xgboost in e:\\python3_8_64bit\\lib\\site-packages (2.1.4)\n",
      "Requirement already satisfied: lightgbm in e:\\python3_8_64bit\\lib\\site-packages (4.6.0)\n",
      "Requirement already satisfied: tensorflow-addons in e:\\python3_8_64bit\\lib\\site-packages (0.21.0)\n",
      "Requirement already satisfied: optuna in e:\\python3_8_64bit\\lib\\site-packages (4.3.0)\n",
      "Requirement already satisfied: imbalanced-learn in e:\\python3_8_64bit\\lib\\site-packages (0.12.4)\n",
      "Requirement already satisfied: torch in e:\\python3_8_64bit\\lib\\site-packages (2.4.1)\n",
      "Requirement already satisfied: schedule in e:\\python3_8_64bit\\lib\\site-packages (1.2.2)\n",
      "Requirement already satisfied: apscheduler in e:\\python3_8_64bit\\lib\\site-packages (3.11.0)\n",
      "Requirement already satisfied: pyarrow in e:\\python3_8_64bit\\lib\\site-packages (17.0.0)\n",
      "Requirement already satisfied: joblib in e:\\python3_8_64bit\\lib\\site-packages (1.4.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in e:\\python3_8_64bit\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\nitro 5\\appdata\\roaming\\python\\python38\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata>=2022.1 in e:\\python3_8_64bit\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\nitro 5\\appdata\\roaming\\python\\python38\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in e:\\python3_8_64bit\\lib\\site-packages (from requests) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in e:\\python3_8_64bit\\lib\\site-packages (from requests) (2025.4.26)\n",
      "Requirement already satisfied: idna<4,>=2.5 in e:\\python3_8_64bit\\lib\\site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in e:\\python3_8_64bit\\lib\\site-packages (from requests) (3.4.2)\n",
      "Requirement already satisfied: colorama>=0.4.6 in c:\\users\\nitro 5\\appdata\\roaming\\python\\python38\\site-packages (from bayesian-optimization) (0.4.6)\n",
      "Requirement already satisfied: scipy>=1.0.0 in e:\\python3_8_64bit\\lib\\site-packages (from bayesian-optimization) (1.10.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in e:\\python3_8_64bit\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\users\\nitro 5\\appdata\\roaming\\python\\python38\\site-packages (from beautifulsoup4) (4.13.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in e:\\python3_8_64bit\\lib\\site-packages (from beautifulsoup4) (2.7)\n",
      "Requirement already satisfied: pillow>=6.2.0 in e:\\python3_8_64bit\\lib\\site-packages (from matplotlib) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in e:\\python3_8_64bit\\lib\\site-packages (from matplotlib) (3.1.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\nitro 5\\appdata\\roaming\\python\\python38\\site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in e:\\python3_8_64bit\\lib\\site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in e:\\python3_8_64bit\\lib\\site-packages (from matplotlib) (6.4.5)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in e:\\python3_8_64bit\\lib\\site-packages (from matplotlib) (1.1.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in e:\\python3_8_64bit\\lib\\site-packages (from matplotlib) (4.57.0)\n",
      "Requirement already satisfied: cycler>=0.10 in e:\\python3_8_64bit\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\nitro 5\\appdata\\roaming\\python\\python38\\site-packages (from importlib-resources>=3.2.0->matplotlib) (3.20.2)\n",
      "Requirement already satisfied: trio~=0.17 in e:\\python3_8_64bit\\lib\\site-packages (from selenium) (0.27.0)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in e:\\python3_8_64bit\\lib\\site-packages (from selenium) (0.12.2)\n",
      "Requirement already satisfied: websocket-client~=1.8 in e:\\python3_8_64bit\\lib\\site-packages (from selenium) (1.8.0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in e:\\python3_8_64bit\\lib\\site-packages (from trio~=0.17->selenium) (1.3.1)\n",
      "Requirement already satisfied: cffi>=1.14 in e:\\python3_8_64bit\\lib\\site-packages (from trio~=0.17->selenium) (1.17.1)\n",
      "Requirement already satisfied: outcome in e:\\python3_8_64bit\\lib\\site-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
      "Requirement already satisfied: exceptiongroup in e:\\python3_8_64bit\\lib\\site-packages (from trio~=0.17->selenium) (1.3.0)\n",
      "Requirement already satisfied: attrs>=23.2.0 in e:\\python3_8_64bit\\lib\\site-packages (from trio~=0.17->selenium) (25.3.0)\n",
      "Requirement already satisfied: sortedcontainers in e:\\python3_8_64bit\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: pycparser in e:\\python3_8_64bit\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.22)\n",
      "Requirement already satisfied: wsproto>=0.14 in e:\\python3_8_64bit\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in e:\\python3_8_64bit\\lib\\site-packages (from urllib3<3,>=1.21.1->requests) (1.7.1)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in e:\\python3_8_64bit\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.16.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.12.0 in e:\\python3_8_64bit\\lib\\site-packages (from tensorflow) (2.12.0)\n",
      "Requirement already satisfied: jax>=0.3.15 in e:\\python3_8_64bit\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (0.4.13)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in e:\\python3_8_64bit\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.70.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in e:\\python3_8_64bit\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (2.12.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in e:\\python3_8_64bit\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (4.25.8)\n",
      "Requirement already satisfied: h5py>=2.9.0 in e:\\python3_8_64bit\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (3.11.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in e:\\python3_8_64bit\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in e:\\python3_8_64bit\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: libclang>=13.0.0 in e:\\python3_8_64bit\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in e:\\python3_8_64bit\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in e:\\python3_8_64bit\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: keras<2.13,>=2.12.0 in e:\\python3_8_64bit\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (2.12.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in e:\\python3_8_64bit\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (25.2.10)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in e:\\python3_8_64bit\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in e:\\python3_8_64bit\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in e:\\python3_8_64bit\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in e:\\python3_8_64bit\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: setuptools in e:\\python3_8_64bit\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (56.0.0)\n",
      "Requirement already satisfied: tensorboard<2.13,>=2.12 in e:\\python3_8_64bit\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (2.12.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in e:\\python3_8_64bit\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.12.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: ml-dtypes>=0.1.0 in e:\\python3_8_64bit\\lib\\site-packages (from jax>=0.3.15->tensorflow-intel==2.12.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.6 in c:\\users\\nitro 5\\appdata\\roaming\\python\\python38\\site-packages (from jax>=0.3.15->tensorflow-intel==2.12.0->tensorflow) (8.5.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in e:\\python3_8_64bit\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.40.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in e:\\python3_8_64bit\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in e:\\python3_8_64bit\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in e:\\python3_8_64bit\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (3.0.6)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in e:\\python3_8_64bit\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in e:\\python3_8_64bit\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (4.9.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in e:\\python3_8_64bit\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (0.4.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in e:\\python3_8_64bit\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (5.5.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in e:\\python3_8_64bit\\lib\\site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.0.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in e:\\python3_8_64bit\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in e:\\python3_8_64bit\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (3.2.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in e:\\python3_8_64bit\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.1.5)\n",
      "Requirement already satisfied: typeguard<3.0.0,>=2.7 in e:\\python3_8_64bit\\lib\\site-packages (from tensorflow-addons) (2.13.3)\n",
      "Requirement already satisfied: PyYAML in e:\\python3_8_64bit\\lib\\site-packages (from optuna) (6.0.2)\n",
      "Requirement already satisfied: tqdm in e:\\python3_8_64bit\\lib\\site-packages (from optuna) (4.67.1)\n",
      "Requirement already satisfied: colorlog in e:\\python3_8_64bit\\lib\\site-packages (from optuna) (6.9.0)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.2 in e:\\python3_8_64bit\\lib\\site-packages (from optuna) (2.0.41)\n",
      "Requirement already satisfied: alembic>=1.5.0 in e:\\python3_8_64bit\\lib\\site-packages (from optuna) (1.14.1)\n",
      "Requirement already satisfied: Mako in e:\\python3_8_64bit\\lib\\site-packages (from alembic>=1.5.0->optuna) (1.3.10)\n",
      "Requirement already satisfied: greenlet>=1 in e:\\python3_8_64bit\\lib\\site-packages (from sqlalchemy>=1.4.2->optuna) (3.1.1)\n",
      "Requirement already satisfied: filelock in e:\\python3_8_64bit\\lib\\site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: fsspec in e:\\python3_8_64bit\\lib\\site-packages (from torch) (2025.3.0)\n",
      "Requirement already satisfied: jinja2 in e:\\python3_8_64bit\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: networkx in e:\\python3_8_64bit\\lib\\site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: sympy in e:\\python3_8_64bit\\lib\\site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: tzlocal>=3.0 in e:\\python3_8_64bit\\lib\\site-packages (from apscheduler) (5.2)\n",
      "Requirement already satisfied: backports.zoneinfo in e:\\python3_8_64bit\\lib\\site-packages (from apscheduler) (0.2.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in e:\\python3_8_64bit\\lib\\site-packages (from sympy->torch) (1.3.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.1.1; however, version 25.0.1 is available.\n",
      "You should consider upgrading via the 'e:\\python3_8_64bit\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "! pip install pandas deap requests bayesian-optimization beautifulsoup4 seaborn selenium matplotlib sklearn tensorflow numpy scikit-learn xgboost lightgbm tensorflow-addons optuna imbalanced-learn torch schedule apscheduler pyarrow joblib\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b93681c",
   "metadata": {},
   "source": [
    "# Xử lý data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "049c4ad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thông tin dữ liệu:\n",
      "- Số cột: 3\n",
      "- Tên cột: ['Ngày Mở Thưởng', 'Kết Quả', 'Giải Jackpot']\n",
      "- Số dòng: 1356\n",
      "- Dữ liệu mẫu (5 dòng đầu):\n",
      "   Ngày Mở Thưởng            Kết Quả    Giải Jackpot\n",
      "0  T4, 28/05/2025  17 22 23 28 31 41  29.736.250.000\n",
      "1  CN, 25/05/2025  05 14 23 24 28 44  25.290.182.500\n",
      "2  T6, 23/05/2025  02 04 15 16 29 43  23.051.056.000\n",
      "3  T4, 21/05/2025  02 13 14 21 24 30  20.908.114.000\n",
      "4  CN, 18/05/2025  06 07 17 27 30 42  18.835.213.500\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Tham số hóa đường dẫn\n",
    "DATA_DIR = \"data_645\"\n",
    "FILE_NAME = \"E:/vietlot_mega\\data_645/vietlott_645_filtered.csv\"\n",
    "FILE_PATH = os.path.join(DATA_DIR, FILE_NAME)\n",
    "\n",
    "# Kiểm tra file tồn tại\n",
    "if not os.path.exists(FILE_PATH):\n",
    "    raise FileNotFoundError(f\"Không tìm thấy file: {FILE_PATH}\")\n",
    "\n",
    "# Đọc dữ liệu\n",
    "try:\n",
    "    df = pd.read_csv(FILE_PATH, sep=\"\\t\")\n",
    "except Exception as e:\n",
    "    raise Exception(f\"Lỗi khi đọc file {FILE_PATH}: {e}\")\n",
    "\n",
    "# Kiểm tra cột\n",
    "expected_columns = ['Ngày Mở Thưởng', 'Kết Quả', 'Giải Jackpot']\n",
    "if not all(col in df.columns for col in expected_columns):\n",
    "    raise ValueError(f\"Dữ liệu thiếu cột: {set(expected_columns) - set(df.columns)}\")\n",
    "\n",
    "# Kiểm tra dữ liệu thiếu\n",
    "if df.isna().any().any():\n",
    "    print(\"Cảnh báo: Dữ liệu có giá trị thiếu:\")\n",
    "    print(df.isna().sum())\n",
    "\n",
    "# In thông tin cơ bản\n",
    "print(\"Thông tin dữ liệu:\")\n",
    "print(f\"- Số cột: {len(df.columns)}\")\n",
    "print(f\"- Tên cột: {list(df.columns)}\")\n",
    "print(f\"- Số dòng: {len(df)}\")\n",
    "print(f\"- Dữ liệu mẫu (5 dòng đầu):\\n{df.head()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9b462334",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cảnh báo: Có giá trị Jackpot không hợp lệ:\n",
      "     Ngày Mở Thưởng  Giải Jackpot\n",
      "0        2025-05-28           NaN\n",
      "1        2025-05-25           NaN\n",
      "2        2025-05-23           NaN\n",
      "3        2025-05-21           NaN\n",
      "4        2025-05-18           NaN\n",
      "...             ...           ...\n",
      "1351     2016-08-05           NaN\n",
      "1352     2016-08-03           NaN\n",
      "1353     2016-07-31           NaN\n",
      "1354     2016-07-29           NaN\n",
      "1355     2016-07-27           NaN\n",
      "\n",
      "[1356 rows x 2 columns]\n",
      "Dữ liệu sau khi xử lý (5 dòng đầu):\n",
      "        Ngày                   Kết Quả  Jackpot\n",
      "0 2025-05-28  [17, 22, 23, 28, 31, 41]      NaN\n",
      "1 2025-05-25   [5, 14, 23, 24, 28, 44]      NaN\n",
      "2 2025-05-23    [2, 4, 15, 16, 29, 43]      NaN\n",
      "3 2025-05-21   [2, 13, 14, 21, 24, 30]      NaN\n",
      "4 2025-05-18    [6, 7, 17, 27, 30, 42]      NaN\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Tham số hóa đường dẫn\n",
    "DATA_DIR = \"data_645\"\n",
    "FILE_NAME = \"vietlott_645_filtered.csv\"\n",
    "FILE_PATH = os.path.join(DATA_DIR, FILE_NAME)\n",
    "\n",
    "# Hàm kiểm tra tính hợp lệ của kết quả\n",
    "def validate_result(result):\n",
    "    try:\n",
    "        if len(result) != 6:\n",
    "            return False, \"Phải có đúng 6 số\"\n",
    "        if not all(isinstance(x, int) and 1 <= x <= 45 for x in result):\n",
    "            return False, \"Số phải trong khoảng 1-45\"\n",
    "        return True, \"\"\n",
    "    except:\n",
    "        return False, \"Định dạng không hợp lệ\"\n",
    "\n",
    "# Đọc dữ liệu\n",
    "try:\n",
    "    df = pd.read_csv(FILE_PATH, sep=\"\\t\", encoding=\"utf-8\")\n",
    "except Exception as e:\n",
    "    raise Exception(f\"Lỗi khi đọc file {FILE_PATH}: {e}\")\n",
    "\n",
    "# Kiểm tra và xử lý cột\n",
    "if 'Kết Quả' in df.columns and 'Ngày Mở Thưởng' in df.columns and 'Giải Jackpot' in df.columns:\n",
    "    # Chuyển đổi Kết Quả từ chuỗi phân cách bởi khoảng trắng sang danh sách số nguyên\n",
    "    df['Kết Quả'] = df['Kết Quả'].apply(lambda x: [int(i) for i in x.split()] if isinstance(x, str) else x)\n",
    "    \n",
    "    # Kiểm tra tính hợp lệ của Kết Quả\n",
    "    df['Valid_Result'] = df['Kết Quả'].apply(validate_result)\n",
    "    invalid_results = df[~df['Valid_Result'].apply(lambda x: x[0])]\n",
    "    if not invalid_results.empty:\n",
    "        print(\"Cảnh báo: Phát hiện kết quả không hợp lệ:\")\n",
    "        print(invalid_results[['Ngày Mở Thưởng', 'Kết Quả', 'Valid_Result']])\n",
    "    \n",
    "    # Xử lý cột Ngày: Loại bỏ tiền tố ngày trong tuần (CN, T6, T4) và chuyển đổi định dạng\n",
    "    try:\n",
    "        # Tách phần ngày (bỏ tiền tố như CN, T6, T4)\n",
    "        df['Ngày Mở Thưởng'] = df['Ngày Mở Thưởng'].str.split(',').str[-1].str.strip()\n",
    "        # Chuyển đổi sang định dạng datetime\n",
    "        df['Ngày Mở Thưởng'] = pd.to_datetime(df['Ngày Mở Thưởng'], format='%d/%m/%Y', dayfirst=True)\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Lỗi khi chuyển đổi cột Ngày: {e}\")\n",
    "    \n",
    "    # Kiểm tra Jackpot\n",
    "    df['Giải Jackpot'] = pd.to_numeric(df['Giải Jackpot'], errors='coerce')\n",
    "    if df['Giải Jackpot'].isna().any():\n",
    "        print(\"Cảnh báo: Có giá trị Jackpot không hợp lệ:\")\n",
    "        print(df[df['Giải Jackpot'].isna()][['Ngày Mở Thưởng', 'Giải Jackpot']])\n",
    "    \n",
    "    # Đổi tên cột cho thống nhất\n",
    "    df = df.rename(columns={'Ngày Mở Thưởng': 'Ngày', 'Giải Jackpot': 'Jackpot'})\n",
    "    \n",
    "    # In dữ liệu mẫu\n",
    "    print(\"Dữ liệu sau khi xử lý (5 dòng đầu):\")\n",
    "    print(df[['Ngày', 'Kết Quả', 'Jackpot']].head())\n",
    "else:\n",
    "    raise ValueError(\"Dữ liệu thiếu cột cần thiết\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6c7538b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Đã ghi file thành công: vietlott_645_clean.csv\n"
     ]
    }
   ],
   "source": [
    "df.to_csv(r\"E:/vietlot_mega/data_645/vietlott_645_clean.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "print(\"✅ Đã ghi file thành công: vietlott_645_clean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dcd94812",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NITRO 5\\AppData\\Local\\Temp\\ipykernel_18208\\3745541686.py:23: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.barplot(x=freq.index, y=freq.values, palette='viridis')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 5 cặp số xuất hiện cùng nhau nhiều nhất:\n",
      "     Cặp số  Tần suất  Tần suất (%)\n",
      "0  (10, 22)        34      2.507375\n",
      "1  (13, 20)        34      2.507375\n",
      "2   (7, 44)        33      2.433628\n",
      "3   (4, 37)        33      2.433628\n",
      "4  (19, 24)        32      2.359882\n",
      "\n",
      "Top 5 bộ ba số xuất hiện cùng nhau nhiều nhất:\n",
      "       Bộ ba số  Tần suất  Tần suất (%)\n",
      "0  (11, 26, 28)         9      0.663717\n",
      "1  (10, 22, 36)         9      0.663717\n",
      "2    (1, 7, 16)         9      0.663717\n",
      "3  (25, 35, 39)         8      0.589971\n",
      "4  (10, 22, 43)         8      0.589971\n",
      "\n",
      "Tần suất tăng/giảm Jackpot:\n",
      "Trend\n",
      "Không đổi    1356\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Giá trị tăng trung bình: nan tỷ VND\n",
      "Giá trị giảm trung bình: nan tỷ VND\n",
      "\n",
      "Phân tích chu kỳ Jackpot:\n",
      "- Số chu kỳ: 1\n",
      "- Độ dài chu kỳ trung bình: 1356.00 kỳ\n",
      "- Độ dài chu kỳ tối đa: 1356 kỳ\n",
      "- Độ dài chu kỳ tối thiểu: 1356 kỳ\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "from itertools import combinations\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Tham số hóa đường dẫn lưu biểu đồ\n",
    "OUTPUT_DIR = \"plots\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Kiểm tra tính hợp lệ của Kết Quả\n",
    "if 'Valid_Result' not in df.columns:\n",
    "    df['Valid_Result'] = df['Kết Quả'].apply(validate_result)\n",
    "invalid_results = df[~df['Valid_Result'].apply(lambda x: x[0])]\n",
    "if not invalid_results.empty:\n",
    "    raise ValueError(\"Dữ liệu chứa kết quả không hợp lệ, vui lòng kiểm tra.\")\n",
    "\n",
    "# 1. Phân tích tần suất số\n",
    "plt.figure(figsize=(15, 6))\n",
    "all_numbers = np.concatenate(df['Kết Quả'].values)\n",
    "freq = pd.Series(all_numbers).value_counts().sort_index()\n",
    "sns.barplot(x=freq.index, y=freq.values, palette='viridis')\n",
    "plt.title('Tần suất xuất hiện của các số (1-45)', fontsize=14)\n",
    "plt.xlabel('Số', fontsize=12)\n",
    "plt.ylabel('Tần suất', fontsize=12)\n",
    "plt.xticks(np.arange(1, 46, 1), rotation=45, fontsize=10)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUTPUT_DIR, 'number_frequency.png'), dpi=300)\n",
    "plt.close()\n",
    "\n",
    "# 2. Phân tích cặp số và bộ ba số\n",
    "pair_counts = Counter()\n",
    "triple_counts = Counter()\n",
    "for result in df['Kết Quả']:\n",
    "    pairs = list(combinations(sorted(result), 2))\n",
    "    pair_counts.update(pairs)\n",
    "    triples = list(combinations(sorted(result), 3))\n",
    "    triple_counts.update(triples)\n",
    "\n",
    "# Chuẩn hóa tần suất\n",
    "num_draws = len(df)\n",
    "top_pairs = pd.DataFrame(pair_counts.most_common(5), columns=['Cặp số', 'Tần suất'])\n",
    "top_pairs['Tần suất (%)'] = top_pairs['Tần suất'] / num_draws * 100\n",
    "print(\"\\nTop 5 cặp số xuất hiện cùng nhau nhiều nhất:\")\n",
    "print(top_pairs[['Cặp số', 'Tần suất', 'Tần suất (%)']])\n",
    "\n",
    "top_triples = pd.DataFrame(triple_counts.most_common(5), columns=['Bộ ba số', 'Tần suất'])\n",
    "top_triples['Tần suất (%)'] = top_triples['Tần suất'] / num_draws * 100\n",
    "print(\"\\nTop 5 bộ ba số xuất hiện cùng nhau nhiều nhất:\")\n",
    "print(top_triples[['Bộ ba số', 'Tần suất', 'Tần suất (%)']])\n",
    "\n",
    "# 3. Phân tích xu hướng Jackpot\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(df['Ngày'], df['Jackpot'] / 1e9, label='Jackpot (tỷ VND)', color='blue')\n",
    "plt.title('Xu hướng giá trị Jackpot theo thời gian', fontsize=14)\n",
    "plt.xlabel('Ngày', fontsize=12)\n",
    "plt.ylabel('Jackpot (tỷ VND)', fontsize=12)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUTPUT_DIR, 'jackpot_trend.png'), dpi=300)\n",
    "plt.close()\n",
    "\n",
    "# 4. Phân tích tăng/giảm Jackpot\n",
    "df['Jackpot_Change'] = df['Jackpot'].diff()\n",
    "df['Trend'] = df['Jackpot_Change'].apply(lambda x: 'Tăng' if x > 0 else 'Giảm' if x < 0 else 'Không đổi')\n",
    "trend_counts = df['Trend'].value_counts()\n",
    "print(\"\\nTần suất tăng/giảm Jackpot:\")\n",
    "print(trend_counts)\n",
    "\n",
    "avg_increase = df[df['Jackpot_Change'] > 0]['Jackpot_Change'].mean() / 1e9\n",
    "avg_decrease = df[df['Jackpot_Change'] < 0]['Jackpot_Change'].mean() / 1e9\n",
    "print(f\"\\nGiá trị tăng trung bình: {avg_increase:.2f} tỷ VND\")\n",
    "print(f\"Giá trị giảm trung bình: {avg_decrease:.2f} tỷ VND\")\n",
    "\n",
    "# 5. Phân tích chu kỳ Jackpot\n",
    "df['Jackpot_Reset'] = df['Jackpot_Change'] < -10e9  # Giả định giảm lớn là reset Jackpot\n",
    "cycles = []\n",
    "current_cycle = 0\n",
    "for reset in df['Jackpot_Reset']:\n",
    "    if reset:\n",
    "        cycles.append(current_cycle)\n",
    "        current_cycle = 0\n",
    "    else:\n",
    "        current_cycle += 1\n",
    "if current_cycle > 0:\n",
    "    cycles.append(current_cycle)\n",
    "\n",
    "print(\"\\nPhân tích chu kỳ Jackpot:\")\n",
    "print(f\"- Số chu kỳ: {len(cycles)}\")\n",
    "print(f\"- Độ dài chu kỳ trung bình: {np.mean(cycles):.2f} kỳ\")\n",
    "print(f\"- Độ dài chu kỳ tối đa: {max(cycles)} kỳ\")\n",
    "print(f\"- Độ dài chu kỳ tối thiểu: {min(cycles)} kỳ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b945c77f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cb46a478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tổng số mẫu học: 1306\n",
      "Đã lưu dữ liệu mã hóa: X.npy, y.npy\n",
      "Kích thước tập huấn luyện: (1044, 50, 45)\n",
      "Kích thước tập kiểm tra: (262, 50, 45)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Tận dụng df từ cell trước\n",
    "# Kiểm tra dữ liệu\n",
    "if 'Kết Quả' not in df.columns:\n",
    "    raise ValueError(\"Dữ liệu thiếu cột 'Kết Quả'\")\n",
    "\n",
    "# Chuyển đổi Kết Quả\n",
    "df['Kết Quả'] = df['Kết Quả'].apply(lambda x: json.loads(x) if isinstance(x, str) else x)\n",
    "\n",
    "# Kiểm tra tính hợp lệ\n",
    "df['Valid_Result'] = df['Kết Quả'].apply(validate_result)\n",
    "invalid_results = df[~df['Valid_Result'].apply(lambda x: x[0])]\n",
    "if not invalid_results.empty:\n",
    "    raise ValueError(\"Dữ liệu chứa kết quả không hợp lệ, vui lòng kiểm tra.\")\n",
    "\n",
    "# Mã hóa dữ liệu\n",
    "mlb = MultiLabelBinarizer(classes=range(1, 46))\n",
    "y_encoded = mlb.fit_transform(df['Kết Quả'])\n",
    "\n",
    "# Tạo chuỗi time-series\n",
    "sequence_length = 50\n",
    "X, y = [], []\n",
    "for i in range(len(y_encoded) - sequence_length):\n",
    "    X.append(y_encoded[i:i + sequence_length])\n",
    "    y.append(y_encoded[i + sequence_length])\n",
    "\n",
    "X = np.array(X)  # (samples, sequence_length, 45)\n",
    "y = np.array(y)  # (samples, 45)\n",
    "print(f\"Tổng số mẫu học: {len(X)}\")\n",
    "\n",
    "# Lưu dữ liệu mã hóa\n",
    "np.save(os.path.join(OUTPUT_DIR, 'X.npy'), X)\n",
    "np.save(os.path.join(OUTPUT_DIR, 'y.npy'), y)\n",
    "print(f\"Đã lưu dữ liệu mã hóa: X.npy, y.npy\")\n",
    "\n",
    "# Chia tập huấn luyện và kiểm tra\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "print(f\"Kích thước tập huấn luyện: {X_train.shape}\")\n",
    "print(f\"Kích thước tập kiểm tra: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cff1d466",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Số kỳ quay trong dữ liệu: 1356\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Đọc dữ liệu\n",
    "df = pd.read_csv(r'E:\\vietlot_mega\\data_645/vietlott_645_clean.csv')\n",
    "\n",
    "# Đếm số kỳ quay\n",
    "num_draws = len(df)\n",
    "\n",
    "print(f\"Số kỳ quay trong dữ liệu: {num_draws}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977c4178",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0fff70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-30 16:27:09,543 - INFO - Đang tải dữ liệu từ E:/vietlot_mega\\data_645/vietlott_645_clean.csv...\n",
      "2025-05-30 16:27:09,563 - INFO - Loại bỏ 0 hàng do kết quả không hợp lệ.\n",
      "2025-05-30 16:27:09,569 - INFO - Đã tải 1356 kết quả hợp lệ.\n"
     ]
    }
   ],
   "source": [
    "def load_and_preprocess_data(file_path='E:/vietlot_mega\\data_645/vietlott_645_clean.csv'):\n",
    "    logger.info(f\"Đang tải dữ liệu từ {file_path}...\")\n",
    "    \n",
    "    # Kiểm tra file tồn tại\n",
    "    if not os.path.exists(file_path):\n",
    "        logger.error(f\"File {file_path} không tồn tại.\")\n",
    "        raise FileNotFoundError(f\"File {file_path} không tồn tại.\")\n",
    "    \n",
    "    # Đọc dữ liệu\n",
    "    df = pd.read_csv(file_path, encoding='utf-8')\n",
    "    if not all(col in df.columns for col in ['Ngày', 'Kết Quả']):\n",
    "        logger.error(\"File CSV thiếu cột 'Ngày' hoặc 'Kết Quả'.\")\n",
    "        raise KeyError(\"File CSV thiếu cột cần thiết.\")\n",
    "    \n",
    "    # Chuyển đổi cột Kết Quả\n",
    "    def parse_results(res):\n",
    "        try:\n",
    "            if isinstance(res, str):\n",
    "                numbers = json.loads(res) if '[' in res else [int(x) for x in res.split()]\n",
    "            else:\n",
    "                numbers = res\n",
    "            if len(numbers) == 6 and all(isinstance(x, int) and 1 <= x <= 45 for x in numbers):\n",
    "                return sorted(numbers)\n",
    "            return None\n",
    "        except Exception:\n",
    "            return None\n",
    "    \n",
    "    initial_rows = len(df)\n",
    "    df['Numbers'] = df['Kết Quả'].apply(parse_results)\n",
    "    df = df.dropna(subset=['Numbers'])\n",
    "    logger.info(f\"Loại bỏ {initial_rows - len(df)} hàng do kết quả không hợp lệ.\")\n",
    "    \n",
    "    # Chuyển đổi ngày\n",
    "    df['Date'] = pd.to_datetime(df['Ngày'], format='%Y-%m-%d', errors='coerce')\n",
    "    df = df.dropna(subset=['Date']).sort_values('Date')\n",
    "    \n",
    "    # Thêm đặc trưng\n",
    "    df['Draw'] = range(1, len(df) + 1)\n",
    "    df['DayOfWeek'] = df['Date'].dt.dayofweek\n",
    "    df['Sum'] = df['Numbers'].apply(sum)\n",
    "    df['OddCount'] = df['Numbers'].apply(lambda x: sum(1 for n in x if n % 2 == 1))\n",
    "    df['Range'] = df['Numbers'].apply(lambda x: max(x) - min(x))\n",
    "    \n",
    "    logger.info(f\"Đã tải {len(df)} kết quả hợp lệ.\")\n",
    "    return df\n",
    "\n",
    "# Tải dữ liệu\n",
    "df = load_and_preprocess_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4542cb0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7e9e897a",
   "metadata": {},
   "source": [
    "# LSTM + GRU + Random Fores + Transformer + Tần xuất"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d00500b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-31 10:20:34,410 - INFO - Bắt đầu dự đoán...\n",
      "2025-05-31 10:20:34,412 - INFO - Đang tải dữ liệu...\n",
      "2025-05-31 10:20:34,458 - INFO - Dữ liệu đã tải: 821 kỳ\n",
      "2025-05-31 10:20:34,459 - INFO - Tính ngày quay tiếp theo...\n",
      "2025-05-31 10:20:34,461 - INFO - Ngày cuối: 2025-05-28 (Thứ Tư)\n",
      "2025-05-31 10:20:34,461 - INFO - Kỳ quay tiếp theo: 823, Ngày: 2025-06-01\n",
      "2025-05-31 10:20:34,463 - INFO - Chuẩn bị chuỗi dữ liệu...\n",
      "2025-05-31 10:20:34,600 - INFO - Tập huấn luyện: (576, 100, 11), Tập kiểm tra: (145, 100, 11)\n",
      "2025-05-31 10:20:34,603 - INFO - Dự đoán bộ số...\n",
      "2025-05-31 10:20:34,604 - INFO - Huấn luyện mô hình...\n",
      "2025-05-31 10:20:34,693 - INFO - Huấn luyện tcn...\n",
      "2025-05-31 10:20:37,154 - INFO - Epoch 1/200 - loss: 3.6544 - val_loss: 3.2235 - precision_at_k: 0.1334\n",
      "2025-05-31 10:20:37,975 - INFO - Epoch 2/200 - loss: 3.3581 - val_loss: 2.9957 - precision_at_k: 0.1768\n",
      "2025-05-31 10:20:38,756 - INFO - Epoch 3/200 - loss: 3.1166 - val_loss: 2.7816 - precision_at_k: 0.2138\n",
      "2025-05-31 10:20:39,590 - INFO - Epoch 4/200 - loss: 2.8936 - val_loss: 2.5751 - precision_at_k: 0.2384\n",
      "2025-05-31 10:20:40,454 - INFO - Epoch 5/200 - loss: 2.6753 - val_loss: 2.3731 - precision_at_k: 0.2824\n",
      "2025-05-31 10:20:41,477 - INFO - Epoch 6/200 - loss: 2.4735 - val_loss: 2.1802 - precision_at_k: 0.3108\n",
      "2025-05-31 10:20:42,399 - INFO - Epoch 7/200 - loss: 2.2731 - val_loss: 2.0036 - precision_at_k: 0.3542\n",
      "2025-05-31 10:20:43,300 - INFO - Epoch 8/200 - loss: 2.0686 - val_loss: 1.8457 - precision_at_k: 0.3967\n",
      "2025-05-31 10:20:44,175 - INFO - Epoch 9/200 - loss: 1.8614 - val_loss: 1.7128 - precision_at_k: 0.4410\n",
      "2025-05-31 10:20:44,955 - INFO - Epoch 10/200 - loss: 1.6860 - val_loss: 1.6134 - precision_at_k: 0.4867\n",
      "2025-05-31 10:20:45,742 - INFO - Epoch 11/200 - loss: 1.5261 - val_loss: 1.5419 - precision_at_k: 0.5174\n",
      "2025-05-31 10:20:46,554 - INFO - Epoch 12/200 - loss: 1.3861 - val_loss: 1.4861 - precision_at_k: 0.5564\n",
      "2025-05-31 10:20:47,349 - INFO - Epoch 13/200 - loss: 1.2674 - val_loss: 1.4354 - precision_at_k: 0.6088\n",
      "2025-05-31 10:20:48,171 - INFO - Epoch 14/200 - loss: 1.1676 - val_loss: 1.3886 - precision_at_k: 0.6473\n",
      "2025-05-31 10:20:49,143 - INFO - Epoch 15/200 - loss: 1.0757 - val_loss: 1.3352 - precision_at_k: 0.6788\n",
      "2025-05-31 10:20:49,994 - INFO - Epoch 16/200 - loss: 0.9948 - val_loss: 1.2896 - precision_at_k: 0.7164\n",
      "2025-05-31 10:20:50,791 - INFO - Epoch 17/200 - loss: 0.9190 - val_loss: 1.2518 - precision_at_k: 0.7514\n",
      "2025-05-31 10:20:51,575 - INFO - Epoch 18/200 - loss: 0.8506 - val_loss: 1.2116 - precision_at_k: 0.7836\n",
      "2025-05-31 10:20:52,362 - INFO - Epoch 19/200 - loss: 0.7862 - val_loss: 1.1763 - precision_at_k: 0.8084\n",
      "2025-05-31 10:20:53,202 - INFO - Epoch 20/200 - loss: 0.7272 - val_loss: 1.1331 - precision_at_k: 0.8290\n",
      "2025-05-31 10:20:54,062 - INFO - Epoch 21/200 - loss: 0.6719 - val_loss: 1.0893 - precision_at_k: 0.8571\n",
      "2025-05-31 10:20:54,906 - INFO - Epoch 22/200 - loss: 0.6213 - val_loss: 1.0537 - precision_at_k: 0.8733\n",
      "2025-05-31 10:20:55,732 - INFO - Epoch 23/200 - loss: 0.5764 - val_loss: 1.0246 - precision_at_k: 0.8889\n",
      "2025-05-31 10:20:56,559 - INFO - Epoch 24/200 - loss: 0.5303 - val_loss: 0.9948 - precision_at_k: 0.9068\n",
      "2025-05-31 10:20:57,387 - INFO - Epoch 25/200 - loss: 0.4930 - val_loss: 0.9762 - precision_at_k: 0.9175\n",
      "2025-05-31 10:20:58,175 - INFO - Epoch 26/200 - loss: 0.4526 - val_loss: 0.9517 - precision_at_k: 0.9355\n",
      "2025-05-31 10:20:58,985 - INFO - Epoch 27/200 - loss: 0.4200 - val_loss: 0.9234 - precision_at_k: 0.9418\n",
      "2025-05-31 10:20:59,765 - INFO - Epoch 28/200 - loss: 0.3883 - val_loss: 0.8981 - precision_at_k: 0.9575\n",
      "2025-05-31 10:21:00,564 - INFO - Epoch 29/200 - loss: 0.3603 - val_loss: 0.8897 - precision_at_k: 0.9589\n",
      "2025-05-31 10:21:01,361 - INFO - Epoch 30/200 - loss: 0.3343 - val_loss: 0.8729 - precision_at_k: 0.9667\n",
      "2025-05-31 10:21:02,158 - INFO - Epoch 31/200 - loss: 0.3083 - val_loss: 0.8647 - precision_at_k: 0.9745\n",
      "2025-05-31 10:21:02,980 - INFO - Epoch 32/200 - loss: 0.2860 - val_loss: 0.8590 - precision_at_k: 0.9783\n",
      "2025-05-31 10:21:03,798 - INFO - Epoch 33/200 - loss: 0.2658 - val_loss: 0.8387 - precision_at_k: 0.9838\n",
      "2025-05-31 10:21:04,622 - INFO - Epoch 34/200 - loss: 0.2480 - val_loss: 0.8087 - precision_at_k: 0.9841\n",
      "2025-05-31 10:21:05,426 - INFO - Epoch 35/200 - loss: 0.2287 - val_loss: 0.7937 - precision_at_k: 0.9867\n",
      "2025-05-31 10:21:06,218 - INFO - Epoch 36/200 - loss: 0.2139 - val_loss: 0.7872 - precision_at_k: 0.9881\n",
      "2025-05-31 10:21:07,057 - INFO - Epoch 37/200 - loss: 0.1995 - val_loss: 0.7733 - precision_at_k: 0.9916\n",
      "2025-05-31 10:21:07,879 - INFO - Epoch 38/200 - loss: 0.1869 - val_loss: 0.7684 - precision_at_k: 0.9925\n",
      "2025-05-31 10:21:08,718 - INFO - Epoch 39/200 - loss: 0.1737 - val_loss: 0.7607 - precision_at_k: 0.9931\n",
      "2025-05-31 10:21:09,559 - INFO - Epoch 40/200 - loss: 0.1617 - val_loss: 0.7486 - precision_at_k: 0.9945\n",
      "2025-05-31 10:21:10,363 - INFO - Epoch 41/200 - loss: 0.1509 - val_loss: 0.7436 - precision_at_k: 0.9962\n",
      "2025-05-31 10:21:11,167 - INFO - Epoch 42/200 - loss: 0.1422 - val_loss: 0.7038 - precision_at_k: 0.9968\n",
      "2025-05-31 10:21:12,013 - INFO - Epoch 43/200 - loss: 0.1334 - val_loss: 0.6988 - precision_at_k: 0.9986\n",
      "2025-05-31 10:21:12,803 - INFO - Epoch 44/200 - loss: 0.1252 - val_loss: 0.6847 - precision_at_k: 0.9951\n",
      "2025-05-31 10:21:13,619 - INFO - Epoch 45/200 - loss: 0.1175 - val_loss: 0.6867 - precision_at_k: 0.9977\n",
      "2025-05-31 10:21:14,438 - INFO - Epoch 46/200 - loss: 0.1118 - val_loss: 0.6959 - precision_at_k: 0.9988\n",
      "2025-05-31 10:21:15,225 - INFO - Epoch 47/200 - loss: 0.1063 - val_loss: 0.6795 - precision_at_k: 0.9986\n",
      "2025-05-31 10:21:16,030 - INFO - Epoch 48/200 - loss: 0.1000 - val_loss: 0.6970 - precision_at_k: 0.9994\n",
      "2025-05-31 10:21:16,831 - INFO - Epoch 49/200 - loss: 0.0953 - val_loss: 0.6908 - precision_at_k: 0.9983\n",
      "2025-05-31 10:21:17,635 - INFO - Epoch 50/200 - loss: 0.0900 - val_loss: 0.6913 - precision_at_k: 0.9991\n",
      "2025-05-31 10:21:18,417 - INFO - Epoch 51/200 - loss: 0.0861 - val_loss: 0.6956 - precision_at_k: 0.9991\n",
      "2025-05-31 10:21:19,193 - INFO - Epoch 52/200 - loss: 0.0828 - val_loss: 0.6594 - precision_at_k: 0.9988\n",
      "2025-05-31 10:21:19,996 - INFO - Epoch 53/200 - loss: 0.0779 - val_loss: 0.6420 - precision_at_k: 0.9991\n",
      "2025-05-31 10:21:20,786 - INFO - Epoch 54/200 - loss: 0.0751 - val_loss: 0.6498 - precision_at_k: 0.9991\n",
      "2025-05-31 10:21:21,549 - INFO - Epoch 55/200 - loss: 0.0717 - val_loss: 0.6739 - precision_at_k: 1.0000\n",
      "2025-05-31 10:21:22,357 - INFO - Epoch 56/200 - loss: 0.0679 - val_loss: 0.6466 - precision_at_k: 1.0000\n",
      "2025-05-31 10:21:23,140 - INFO - Epoch 57/200 - loss: 0.0660 - val_loss: 0.6755 - precision_at_k: 0.9997\n",
      "2025-05-31 10:21:23,940 - INFO - Epoch 58/200 - loss: 0.0639 - val_loss: 0.7020 - precision_at_k: 0.9994\n",
      "2025-05-31 10:21:24,714 - INFO - Epoch 59/200 - loss: 0.0617 - val_loss: 0.6614 - precision_at_k: 0.9997\n",
      "2025-05-31 10:21:25,517 - INFO - Epoch 60/200 - loss: 0.0602 - val_loss: 0.5826 - precision_at_k: 0.9997\n",
      "2025-05-31 10:21:26,303 - INFO - Epoch 61/200 - loss: 0.0574 - val_loss: 0.5570 - precision_at_k: 1.0000\n",
      "2025-05-31 10:21:27,119 - INFO - Epoch 62/200 - loss: 0.0559 - val_loss: 0.6006 - precision_at_k: 1.0000\n",
      "2025-05-31 10:21:28,020 - INFO - Epoch 63/200 - loss: 0.0551 - val_loss: 0.6492 - precision_at_k: 0.9994\n",
      "2025-05-31 10:21:28,927 - INFO - Epoch 64/200 - loss: 0.0526 - val_loss: 0.6433 - precision_at_k: 1.0000\n",
      "2025-05-31 10:21:29,959 - INFO - Epoch 65/200 - loss: 0.0512 - val_loss: 0.6911 - precision_at_k: 1.0000\n",
      "2025-05-31 10:21:31,030 - INFO - Epoch 66/200 - loss: 0.0494 - val_loss: 0.6277 - precision_at_k: 0.9997\n",
      "2025-05-31 10:21:32,001 - INFO - Epoch 67/200 - loss: 0.0478 - val_loss: 0.6146 - precision_at_k: 1.0000\n",
      "2025-05-31 10:21:33,036 - INFO - Epoch 68/200 - loss: 0.0464 - val_loss: 0.6368 - precision_at_k: 1.0000\n",
      "2025-05-31 10:21:34,081 - INFO - Epoch 69/200 - loss: 0.0454 - val_loss: 0.6616 - precision_at_k: 1.0000\n",
      "2025-05-31 10:21:35,020 - INFO - Epoch 70/200 - loss: 0.0433 - val_loss: 0.6323 - precision_at_k: 1.0000\n",
      "2025-05-31 10:21:35,954 - INFO - Epoch 71/200 - loss: 0.0418 - val_loss: 0.6508 - precision_at_k: 0.9997\n",
      "2025-05-31 10:21:36,914 - INFO - Epoch 72/200 - loss: 0.0411 - val_loss: 0.6223 - precision_at_k: 1.0000\n",
      "2025-05-31 10:21:38,051 - INFO - Epoch 73/200 - loss: 0.0398 - val_loss: 0.5987 - precision_at_k: 1.0000\n",
      "2025-05-31 10:21:39,285 - INFO - Epoch 74/200 - loss: 0.0389 - val_loss: 0.6174 - precision_at_k: 1.0000\n",
      "2025-05-31 10:21:40,571 - INFO - Epoch 75/200 - loss: 0.0386 - val_loss: 0.6211 - precision_at_k: 0.9997\n",
      "2025-05-31 10:21:41,559 - INFO - Epoch 76/200 - loss: 0.0376 - val_loss: 0.6425 - precision_at_k: 1.0000\n",
      "2025-05-31 10:21:42,248 - INFO - tcn - Match 3+: 0.048, Match 4+: 0.007\n",
      "2025-05-31 10:21:42,249 - INFO - Huấn luyện lstm...\n",
      "2025-05-31 10:22:10,283 - INFO - Epoch 1/200 - loss: 0.8407 - val_loss: 0.6892 - precision_at_k: 0.1400\n",
      "2025-05-31 10:22:30,805 - INFO - Epoch 2/200 - loss: 0.7806 - val_loss: 0.6857 - precision_at_k: 0.1557\n",
      "2025-05-31 10:22:50,689 - INFO - Epoch 3/200 - loss: 0.7608 - val_loss: 0.6800 - precision_at_k: 0.1557\n",
      "2025-05-31 10:23:10,456 - INFO - Epoch 4/200 - loss: 0.7509 - val_loss: 0.6765 - precision_at_k: 0.1649\n",
      "2025-05-31 10:23:28,719 - INFO - Epoch 5/200 - loss: 0.7406 - val_loss: 0.6706 - precision_at_k: 0.1713\n",
      "2025-05-31 10:23:46,259 - INFO - Epoch 6/200 - loss: 0.7354 - val_loss: 0.6666 - precision_at_k: 0.1753\n",
      "2025-05-31 10:24:04,270 - INFO - Epoch 7/200 - loss: 0.7259 - val_loss: 0.6641 - precision_at_k: 0.1843\n",
      "2025-05-31 10:24:21,474 - INFO - Epoch 8/200 - loss: 0.7219 - val_loss: 0.6617 - precision_at_k: 0.1756\n",
      "2025-05-31 10:24:38,185 - INFO - Epoch 9/200 - loss: 0.7097 - val_loss: 0.6539 - precision_at_k: 0.1863\n",
      "2025-05-31 10:24:55,480 - INFO - Epoch 10/200 - loss: 0.7058 - val_loss: 0.6460 - precision_at_k: 0.1765\n",
      "2025-05-31 10:25:14,411 - INFO - Epoch 11/200 - loss: 0.6939 - val_loss: 0.6408 - precision_at_k: 0.1913\n",
      "2025-05-31 10:25:32,911 - INFO - Epoch 12/200 - loss: 0.6900 - val_loss: 0.6371 - precision_at_k: 0.2066\n",
      "2025-05-31 10:25:49,296 - INFO - Epoch 13/200 - loss: 0.6777 - val_loss: 0.6298 - precision_at_k: 0.1875\n",
      "2025-05-31 10:26:08,082 - INFO - Epoch 14/200 - loss: 0.6740 - val_loss: 0.6224 - precision_at_k: 0.1892\n",
      "2025-05-31 10:26:26,858 - INFO - Epoch 15/200 - loss: 0.6626 - val_loss: 0.6111 - precision_at_k: 0.1910\n",
      "2025-05-31 10:26:45,651 - INFO - Epoch 16/200 - loss: 0.6524 - val_loss: 0.5998 - precision_at_k: 0.1985\n",
      "2025-05-31 10:27:04,713 - INFO - Epoch 17/200 - loss: 0.6423 - val_loss: 0.5918 - precision_at_k: 0.2101\n",
      "2025-05-31 10:27:23,826 - INFO - Epoch 18/200 - loss: 0.6313 - val_loss: 0.5804 - precision_at_k: 0.1976\n",
      "2025-05-31 10:27:42,831 - INFO - Epoch 19/200 - loss: 0.6210 - val_loss: 0.5731 - precision_at_k: 0.2121\n",
      "2025-05-31 10:28:01,558 - INFO - Epoch 20/200 - loss: 0.6075 - val_loss: 0.5650 - precision_at_k: 0.2115\n",
      "2025-05-31 10:28:20,253 - INFO - Epoch 21/200 - loss: 0.5965 - val_loss: 0.5546 - precision_at_k: 0.2228\n",
      "2025-05-31 10:28:39,039 - INFO - Epoch 22/200 - loss: 0.5779 - val_loss: 0.5380 - precision_at_k: 0.2240\n",
      "2025-05-31 10:28:57,875 - INFO - Epoch 23/200 - loss: 0.5690 - val_loss: 0.5317 - precision_at_k: 0.2289\n",
      "2025-05-31 10:29:17,499 - INFO - Epoch 24/200 - loss: 0.5562 - val_loss: 0.5171 - precision_at_k: 0.2133\n",
      "2025-05-31 10:29:36,357 - INFO - Epoch 25/200 - loss: 0.5399 - val_loss: 0.5186 - precision_at_k: 0.2245\n",
      "2025-05-31 10:29:55,187 - INFO - Epoch 26/200 - loss: 0.5312 - val_loss: 0.5165 - precision_at_k: 0.2202\n",
      "2025-05-31 10:30:14,809 - INFO - Epoch 27/200 - loss: 0.5183 - val_loss: 0.4826 - precision_at_k: 0.2283\n",
      "2025-05-31 10:30:33,621 - INFO - Epoch 28/200 - loss: 0.5006 - val_loss: 0.4689 - precision_at_k: 0.2381\n",
      "2025-05-31 10:30:52,447 - INFO - Epoch 29/200 - loss: 0.4976 - val_loss: 0.4660 - precision_at_k: 0.2306\n",
      "2025-05-31 10:31:11,341 - INFO - Epoch 30/200 - loss: 0.4843 - val_loss: 0.4629 - precision_at_k: 0.2347\n",
      "2025-05-31 10:31:30,281 - INFO - Epoch 31/200 - loss: 0.4727 - val_loss: 0.4419 - precision_at_k: 0.2390\n",
      "2025-05-31 10:31:49,697 - INFO - Epoch 32/200 - loss: 0.4616 - val_loss: 0.4426 - precision_at_k: 0.2419\n",
      "2025-05-31 10:32:09,595 - INFO - Epoch 33/200 - loss: 0.4462 - val_loss: 0.4334 - precision_at_k: 0.2500\n",
      "2025-05-31 10:32:28,814 - INFO - Epoch 34/200 - loss: 0.4415 - val_loss: 0.4251 - precision_at_k: 0.2445\n",
      "2025-05-31 10:32:48,571 - INFO - Epoch 35/200 - loss: 0.4340 - val_loss: 0.4216 - precision_at_k: 0.2378\n",
      "2025-05-31 10:33:07,997 - INFO - Epoch 36/200 - loss: 0.4283 - val_loss: 0.4193 - precision_at_k: 0.2555\n",
      "2025-05-31 10:33:27,137 - INFO - Epoch 37/200 - loss: 0.4209 - val_loss: 0.4274 - precision_at_k: 0.2622\n",
      "2025-05-31 10:33:46,636 - INFO - Epoch 38/200 - loss: 0.4146 - val_loss: 0.4244 - precision_at_k: 0.2619\n",
      "2025-05-31 10:34:06,726 - INFO - Epoch 39/200 - loss: 0.4102 - val_loss: 0.4185 - precision_at_k: 0.2610\n",
      "2025-05-31 10:34:25,923 - INFO - Epoch 40/200 - loss: 0.4030 - val_loss: 0.4064 - precision_at_k: 0.2679\n",
      "2025-05-31 10:34:42,797 - INFO - Epoch 41/200 - loss: 0.3993 - val_loss: 0.4086 - precision_at_k: 0.2763\n",
      "2025-05-31 10:35:00,823 - INFO - Epoch 42/200 - loss: 0.3989 - val_loss: 0.4100 - precision_at_k: 0.2795\n",
      "2025-05-31 10:35:21,468 - INFO - Epoch 43/200 - loss: 0.3930 - val_loss: 0.4047 - precision_at_k: 0.2818\n",
      "2025-05-31 10:35:38,120 - INFO - Epoch 44/200 - loss: 0.3876 - val_loss: 0.4050 - precision_at_k: 0.2865\n",
      "2025-05-31 10:35:54,485 - INFO - Epoch 45/200 - loss: 0.3870 - val_loss: 0.4037 - precision_at_k: 0.2827\n",
      "2025-05-31 10:36:10,662 - INFO - Epoch 46/200 - loss: 0.3831 - val_loss: 0.4060 - precision_at_k: 0.2986\n",
      "2025-05-31 10:36:27,170 - INFO - Epoch 47/200 - loss: 0.3839 - val_loss: 0.4104 - precision_at_k: 0.2876\n",
      "2025-05-31 10:36:43,922 - INFO - Epoch 48/200 - loss: 0.3815 - val_loss: 0.4100 - precision_at_k: 0.2847\n",
      "2025-05-31 10:37:01,374 - INFO - Epoch 49/200 - loss: 0.3813 - val_loss: 0.4096 - precision_at_k: 0.3012\n",
      "2025-05-31 10:37:18,958 - INFO - Epoch 50/200 - loss: 0.3774 - val_loss: 0.4085 - precision_at_k: 0.2922\n",
      "2025-05-31 10:37:36,468 - INFO - Epoch 51/200 - loss: 0.3759 - val_loss: 0.4113 - precision_at_k: 0.3006\n",
      "2025-05-31 10:37:54,174 - INFO - Epoch 52/200 - loss: 0.3760 - val_loss: 0.4115 - precision_at_k: 0.3067\n",
      "2025-05-31 10:38:13,772 - INFO - Epoch 53/200 - loss: 0.3721 - val_loss: 0.4171 - precision_at_k: 0.3102\n",
      "2025-05-31 10:38:33,650 - INFO - Epoch 54/200 - loss: 0.3740 - val_loss: 0.4122 - precision_at_k: 0.3137\n",
      "2025-05-31 10:38:53,416 - INFO - Epoch 55/200 - loss: 0.3693 - val_loss: 0.4134 - precision_at_k: 0.3134\n",
      "2025-05-31 10:39:11,702 - INFO - Epoch 56/200 - loss: 0.3667 - val_loss: 0.4142 - precision_at_k: 0.3255\n",
      "2025-05-31 10:39:30,452 - INFO - Epoch 57/200 - loss: 0.3689 - val_loss: 0.4224 - precision_at_k: 0.3154\n",
      "2025-05-31 10:39:49,553 - INFO - Epoch 58/200 - loss: 0.3695 - val_loss: 0.4179 - precision_at_k: 0.3232\n",
      "2025-05-31 10:40:08,603 - INFO - Epoch 59/200 - loss: 0.3675 - val_loss: 0.4218 - precision_at_k: 0.3287\n",
      "2025-05-31 10:40:28,021 - INFO - Epoch 60/200 - loss: 0.3666 - val_loss: 0.4180 - precision_at_k: 0.3223\n",
      "2025-05-31 10:40:29,129 - INFO - lstm - Match 3+: 0.028, Match 4+: 0.000\n",
      "2025-05-31 10:40:29,130 - INFO - Huấn luyện gru...\n",
      "2025-05-31 10:40:47,910 - INFO - Epoch 1/200 - loss: 0.8696 - val_loss: 0.6898 - precision_at_k: 0.1424\n",
      "2025-05-31 10:41:03,682 - INFO - Epoch 2/200 - loss: 0.8060 - val_loss: 0.6822 - precision_at_k: 0.1505\n",
      "2025-05-31 10:41:19,190 - INFO - Epoch 3/200 - loss: 0.7763 - val_loss: 0.6776 - precision_at_k: 0.1502\n",
      "2025-05-31 10:41:34,264 - INFO - Epoch 4/200 - loss: 0.7595 - val_loss: 0.6763 - precision_at_k: 0.1623\n",
      "2025-05-31 10:41:49,483 - INFO - Epoch 5/200 - loss: 0.7496 - val_loss: 0.6705 - precision_at_k: 0.1597\n",
      "2025-05-31 10:42:04,698 - INFO - Epoch 6/200 - loss: 0.7420 - val_loss: 0.6651 - precision_at_k: 0.1617\n",
      "2025-05-31 10:42:19,993 - INFO - Epoch 7/200 - loss: 0.7284 - val_loss: 0.6592 - precision_at_k: 0.1672\n",
      "2025-05-31 10:42:35,127 - INFO - Epoch 8/200 - loss: 0.7235 - val_loss: 0.6540 - precision_at_k: 0.1716\n",
      "2025-05-31 10:42:50,551 - INFO - Epoch 9/200 - loss: 0.7187 - val_loss: 0.6503 - precision_at_k: 0.1690\n",
      "2025-05-31 10:43:05,595 - INFO - Epoch 10/200 - loss: 0.7093 - val_loss: 0.6465 - precision_at_k: 0.1753\n",
      "2025-05-31 10:43:21,099 - INFO - Epoch 11/200 - loss: 0.6991 - val_loss: 0.6373 - precision_at_k: 0.1855\n",
      "2025-05-31 10:43:36,320 - INFO - Epoch 12/200 - loss: 0.6880 - val_loss: 0.6262 - precision_at_k: 0.1947\n",
      "2025-05-31 10:43:51,703 - INFO - Epoch 13/200 - loss: 0.6829 - val_loss: 0.6209 - precision_at_k: 0.1921\n",
      "2025-05-31 10:44:07,075 - INFO - Epoch 14/200 - loss: 0.6760 - val_loss: 0.6172 - precision_at_k: 0.1762\n",
      "2025-05-31 10:44:23,063 - INFO - Epoch 15/200 - loss: 0.6671 - val_loss: 0.6068 - precision_at_k: 0.1970\n",
      "2025-05-31 10:44:38,788 - INFO - Epoch 16/200 - loss: 0.6573 - val_loss: 0.5942 - precision_at_k: 0.1921\n",
      "2025-05-31 10:44:54,317 - INFO - Epoch 17/200 - loss: 0.6453 - val_loss: 0.5871 - precision_at_k: 0.1901\n",
      "2025-05-31 10:45:09,652 - INFO - Epoch 18/200 - loss: 0.6396 - val_loss: 0.5837 - precision_at_k: 0.1910\n",
      "2025-05-31 10:45:24,846 - INFO - Epoch 19/200 - loss: 0.6217 - val_loss: 0.5823 - precision_at_k: 0.1973\n",
      "2025-05-31 10:45:40,206 - INFO - Epoch 20/200 - loss: 0.6174 - val_loss: 0.5751 - precision_at_k: 0.1918\n",
      "2025-05-31 10:45:55,727 - INFO - Epoch 21/200 - loss: 0.6001 - val_loss: 0.5664 - precision_at_k: 0.1979\n",
      "2025-05-31 10:46:11,021 - INFO - Epoch 22/200 - loss: 0.5903 - val_loss: 0.5558 - precision_at_k: 0.1889\n",
      "2025-05-31 10:46:26,297 - INFO - Epoch 23/200 - loss: 0.5720 - val_loss: 0.5378 - precision_at_k: 0.2037\n",
      "2025-05-31 10:46:41,499 - INFO - Epoch 24/200 - loss: 0.5610 - val_loss: 0.5228 - precision_at_k: 0.2014\n",
      "2025-05-31 10:46:56,843 - INFO - Epoch 25/200 - loss: 0.5474 - val_loss: 0.5244 - precision_at_k: 0.2023\n",
      "2025-05-31 10:47:12,847 - INFO - Epoch 26/200 - loss: 0.5374 - val_loss: 0.5142 - precision_at_k: 0.2063\n",
      "2025-05-31 10:47:28,575 - INFO - Epoch 27/200 - loss: 0.5188 - val_loss: 0.5025 - precision_at_k: 0.2092\n",
      "2025-05-31 10:47:43,928 - INFO - Epoch 28/200 - loss: 0.5095 - val_loss: 0.4927 - precision_at_k: 0.2121\n",
      "2025-05-31 10:47:59,389 - INFO - Epoch 29/200 - loss: 0.5024 - val_loss: 0.4906 - precision_at_k: 0.2052\n",
      "2025-05-31 10:48:14,962 - INFO - Epoch 30/200 - loss: 0.4843 - val_loss: 0.4722 - precision_at_k: 0.2121\n",
      "2025-05-31 10:48:30,358 - INFO - Epoch 31/200 - loss: 0.4782 - val_loss: 0.4743 - precision_at_k: 0.2231\n",
      "2025-05-31 10:48:46,616 - INFO - Epoch 32/200 - loss: 0.4702 - val_loss: 0.4799 - precision_at_k: 0.2355\n",
      "2025-05-31 10:49:02,512 - INFO - Epoch 33/200 - loss: 0.4579 - val_loss: 0.4543 - precision_at_k: 0.2211\n",
      "2025-05-31 10:49:18,472 - INFO - Epoch 34/200 - loss: 0.4487 - val_loss: 0.4535 - precision_at_k: 0.2231\n",
      "2025-05-31 10:49:34,026 - INFO - Epoch 35/200 - loss: 0.4410 - val_loss: 0.4446 - precision_at_k: 0.2396\n",
      "2025-05-31 10:49:49,545 - INFO - Epoch 36/200 - loss: 0.4369 - val_loss: 0.4306 - precision_at_k: 0.2309\n",
      "2025-05-31 10:50:05,613 - INFO - Epoch 37/200 - loss: 0.4286 - val_loss: 0.4352 - precision_at_k: 0.2390\n",
      "2025-05-31 10:50:21,576 - INFO - Epoch 38/200 - loss: 0.4222 - val_loss: 0.4330 - precision_at_k: 0.2445\n",
      "2025-05-31 10:50:37,353 - INFO - Epoch 39/200 - loss: 0.4170 - val_loss: 0.4235 - precision_at_k: 0.2459\n",
      "2025-05-31 10:50:53,210 - INFO - Epoch 40/200 - loss: 0.4146 - val_loss: 0.4167 - precision_at_k: 0.2486\n",
      "2025-05-31 10:51:09,204 - INFO - Epoch 41/200 - loss: 0.4092 - val_loss: 0.4127 - precision_at_k: 0.2549\n",
      "2025-05-31 10:51:25,562 - INFO - Epoch 42/200 - loss: 0.4045 - val_loss: 0.4119 - precision_at_k: 0.2642\n",
      "2025-05-31 10:51:41,479 - INFO - Epoch 43/200 - loss: 0.4002 - val_loss: 0.4059 - precision_at_k: 0.2578\n",
      "2025-05-31 10:51:55,299 - INFO - Epoch 44/200 - loss: 0.3997 - val_loss: 0.4074 - precision_at_k: 0.2491\n",
      "2025-05-31 10:52:09,609 - INFO - Epoch 45/200 - loss: 0.3963 - val_loss: 0.4075 - precision_at_k: 0.2538\n",
      "2025-05-31 10:52:23,550 - INFO - Epoch 46/200 - loss: 0.3930 - val_loss: 0.4076 - precision_at_k: 0.2662\n",
      "2025-05-31 10:52:37,045 - INFO - Epoch 47/200 - loss: 0.3930 - val_loss: 0.4064 - precision_at_k: 0.2624\n",
      "2025-05-31 10:52:51,946 - INFO - Epoch 48/200 - loss: 0.3882 - val_loss: 0.4028 - precision_at_k: 0.2694\n",
      "2025-05-31 10:53:05,124 - INFO - Epoch 49/200 - loss: 0.3870 - val_loss: 0.4037 - precision_at_k: 0.2711\n",
      "2025-05-31 10:53:18,205 - INFO - Epoch 50/200 - loss: 0.3867 - val_loss: 0.4048 - precision_at_k: 0.2729\n",
      "2025-05-31 10:53:31,201 - INFO - Epoch 51/200 - loss: 0.3819 - val_loss: 0.4049 - precision_at_k: 0.2784\n",
      "2025-05-31 10:53:45,666 - INFO - Epoch 52/200 - loss: 0.3836 - val_loss: 0.4055 - precision_at_k: 0.2908\n",
      "2025-05-31 10:54:01,562 - INFO - Epoch 53/200 - loss: 0.3813 - val_loss: 0.4085 - precision_at_k: 0.2983\n",
      "2025-05-31 10:54:17,176 - INFO - Epoch 54/200 - loss: 0.3783 - val_loss: 0.4067 - precision_at_k: 0.2824\n",
      "2025-05-31 10:54:32,114 - INFO - Epoch 55/200 - loss: 0.3793 - val_loss: 0.4077 - precision_at_k: 0.2905\n",
      "2025-05-31 10:54:47,292 - INFO - Epoch 56/200 - loss: 0.3786 - val_loss: 0.4088 - precision_at_k: 0.3001\n",
      "2025-05-31 10:55:02,053 - INFO - Epoch 57/200 - loss: 0.3749 - val_loss: 0.4107 - precision_at_k: 0.3030\n",
      "2025-05-31 10:55:15,571 - INFO - Epoch 58/200 - loss: 0.3751 - val_loss: 0.4110 - precision_at_k: 0.2989\n",
      "2025-05-31 10:55:29,201 - INFO - Epoch 59/200 - loss: 0.3757 - val_loss: 0.4114 - precision_at_k: 0.3001\n",
      "2025-05-31 10:55:42,657 - INFO - Epoch 60/200 - loss: 0.3743 - val_loss: 0.4109 - precision_at_k: 0.3119\n",
      "2025-05-31 10:55:56,140 - INFO - Epoch 61/200 - loss: 0.3725 - val_loss: 0.4134 - precision_at_k: 0.3087\n",
      "2025-05-31 10:56:09,565 - INFO - Epoch 62/200 - loss: 0.3747 - val_loss: 0.4115 - precision_at_k: 0.2960\n",
      "2025-05-31 10:56:23,034 - INFO - Epoch 63/200 - loss: 0.3710 - val_loss: 0.4107 - precision_at_k: 0.3061\n",
      "2025-05-31 10:56:23,833 - INFO - gru - Match 3+: 0.034, Match 4+: 0.000\n",
      "2025-05-31 10:56:23,833 - INFO - Huấn luyện transformer...\n",
      "2025-05-31 10:56:28,182 - INFO - Epoch 1/200 - loss: 0.6555 - val_loss: 0.4293 - precision_at_k: 0.1427\n",
      "2025-05-31 10:56:30,607 - INFO - Epoch 2/200 - loss: 0.4230 - val_loss: 0.4263 - precision_at_k: 0.1403\n",
      "2025-05-31 10:56:33,035 - INFO - Epoch 3/200 - loss: 0.4095 - val_loss: 0.4048 - precision_at_k: 0.1438\n",
      "2025-05-31 10:56:35,467 - INFO - Epoch 4/200 - loss: 0.3979 - val_loss: 0.4022 - precision_at_k: 0.1432\n",
      "2025-05-31 10:56:37,909 - INFO - Epoch 5/200 - loss: 0.3938 - val_loss: 0.4020 - precision_at_k: 0.1548\n",
      "2025-05-31 10:56:40,335 - INFO - Epoch 6/200 - loss: 0.3921 - val_loss: 0.3994 - precision_at_k: 0.1710\n",
      "2025-05-31 10:56:42,791 - INFO - Epoch 7/200 - loss: 0.3904 - val_loss: 0.3991 - precision_at_k: 0.1756\n",
      "2025-05-31 10:56:45,230 - INFO - Epoch 8/200 - loss: 0.3897 - val_loss: 0.3997 - precision_at_k: 0.1791\n",
      "2025-05-31 10:56:47,656 - INFO - Epoch 9/200 - loss: 0.3884 - val_loss: 0.3990 - precision_at_k: 0.1837\n",
      "2025-05-31 10:56:50,104 - INFO - Epoch 10/200 - loss: 0.3874 - val_loss: 0.4003 - precision_at_k: 0.1878\n",
      "2025-05-31 10:56:52,557 - INFO - Epoch 11/200 - loss: 0.3857 - val_loss: 0.3990 - precision_at_k: 0.2066\n",
      "2025-05-31 10:56:54,992 - INFO - Epoch 12/200 - loss: 0.3844 - val_loss: 0.4001 - precision_at_k: 0.2083\n",
      "2025-05-31 10:56:57,437 - INFO - Epoch 13/200 - loss: 0.3828 - val_loss: 0.4004 - precision_at_k: 0.2347\n",
      "2025-05-31 10:56:59,830 - INFO - Epoch 14/200 - loss: 0.3809 - val_loss: 0.4025 - precision_at_k: 0.2312\n",
      "2025-05-31 10:57:02,287 - INFO - Epoch 15/200 - loss: 0.3778 - val_loss: 0.4027 - precision_at_k: 0.2491\n",
      "2025-05-31 10:57:04,712 - INFO - Epoch 16/200 - loss: 0.3761 - val_loss: 0.4037 - precision_at_k: 0.2627\n",
      "2025-05-31 10:57:07,157 - INFO - Epoch 17/200 - loss: 0.3742 - val_loss: 0.4050 - precision_at_k: 0.2723\n",
      "2025-05-31 10:57:09,619 - INFO - Epoch 18/200 - loss: 0.3719 - val_loss: 0.4075 - precision_at_k: 0.2737\n",
      "2025-05-31 10:57:12,062 - INFO - Epoch 19/200 - loss: 0.3694 - val_loss: 0.4100 - precision_at_k: 0.2812\n",
      "2025-05-31 10:57:14,512 - INFO - Epoch 20/200 - loss: 0.3665 - val_loss: 0.4136 - precision_at_k: 0.2957\n",
      "2025-05-31 10:57:16,925 - INFO - Epoch 21/200 - loss: 0.3632 - val_loss: 0.4176 - precision_at_k: 0.3015\n",
      "2025-05-31 10:57:19,348 - INFO - Epoch 22/200 - loss: 0.3603 - val_loss: 0.4191 - precision_at_k: 0.3108\n",
      "2025-05-31 10:57:21,794 - INFO - Epoch 23/200 - loss: 0.3581 - val_loss: 0.4219 - precision_at_k: 0.3206\n",
      "2025-05-31 10:57:24,240 - INFO - Epoch 24/200 - loss: 0.3561 - val_loss: 0.4232 - precision_at_k: 0.3241\n",
      "2025-05-31 10:57:24,587 - INFO - transformer - Match 3+: 0.021, Match 4+: 0.000\n",
      "2025-05-31 10:57:24,588 - INFO - Huấn luyện Random Forest...\n",
      "2025-05-31 10:58:07,585 - INFO - rf - Match 3+: 0.014, Match 4+: 0.000\n",
      "2025-05-31 10:58:12,720 - INFO - Dự đoán cuối cùng cho kỳ 823 (2025-06-01): [4, 5, 7, 10, 15, 19]\n",
      "2025-05-31 10:58:12,755 - INFO - Hoàn tất dự đoán cho kỳ 823\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DỰ ĐOÁN CHO KỲ 823 (2025-06-01):\n",
      "Số dự đoán: [4, 5, 7, 10, 15, 19]\n",
      "Số chung: [4, 5, 7, 10, 15, 19, 20, 35, 37, 41]\n",
      "\n",
      "DỰ ĐOÁN TỪ MÔ HÌNH:\n",
      "Tcn: [3, 24, 29, 34, 35, 41]\n",
      "Lstm: [10, 15, 19, 20, 35, 41]\n",
      "Gru: [4, 7, 15, 19, 36, 37]\n",
      "Transformer: [5, 5, 10, 20, 21, 31]\n",
      "Rf: [4, 7, 10, 27, 33, 40]\n",
      "Frequency: [5, 7, 8, 9, 20, 37]\n",
      "Ensemble: [4, 7, 19, 20, 25, 35]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ast import literal_eval\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, Dense, Dropout, Flatten, LSTM, GRU, MultiHeadAttention, LayerNormalization, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, Callback\n",
    "from tensorflow.keras.metrics import Precision\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import tensorflow as tf\n",
    "import random\n",
    "from collections import Counter\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "import logging\n",
    "import warnings\n",
    "\n",
    "# Thiết lập logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s', handlers=[logging.StreamHandler()])\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Thiết lập seed\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "tf.random.set_seed(RANDOM_SEED)\n",
    "random.seed(RANDOM_SEED)\n",
    "\n",
    "# Cấu hình nâng cấp\n",
    "CONFIG = {\n",
    "    'file_path': 'E:\\\\vietlot_mega\\\\data_645\\\\vietlott_645_clean.csv',\n",
    "    'sequence_length': 100,  # Tăng để học mẫu dài hơn\n",
    "    'tcn_filters': [256, 128, 64],  # Tăng bộ lọc\n",
    "    'lstm_units': [256, 128],  # Tăng đơn vị\n",
    "    'gru_units': [256, 128],  # Tăng đơn vị\n",
    "    'rf_estimators': 500,  # Tăng số cây\n",
    "    'transformer_heads': 8,  # Tăng đầu chú ý\n",
    "    'learning_rate': 0.0005,  # Giảm để ổn định\n",
    "    'batch_size': 64,  # Tăng để xử lý nhanh\n",
    "    'epochs': 200,  # Tăng để học kỹ hơn\n",
    "    'dropout_rate': 0.3,\n",
    "    'hist_ratio': 0.3\n",
    "}\n",
    "\n",
    "# Callback in số liệu huấn luyện\n",
    "class PrintTrainingMetrics(Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logging.info(f\"Epoch {epoch+1}/{self.params['epochs']} - \"\n",
    "                     f\"loss: {logs['loss']:.4f} - val_loss: {logs['val_loss']:.4f} - \"\n",
    "                     f\"precision_at_k: {logs.get('precision_at_k', 0):.4f}\")\n",
    "\n",
    "class VietlottPredictor:\n",
    "    def __init__(self, config=CONFIG):\n",
    "        self.config = config\n",
    "        self.df = None\n",
    "        self.results = None\n",
    "        self.scaler = MinMaxScaler()\n",
    "        self.feature_scaler = MinMaxScaler()\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = None, None, None, None\n",
    "        self.last_sequence = None\n",
    "        self.statistical_patterns = {}\n",
    "        self.next_draw = None\n",
    "        self.next_date = None\n",
    "\n",
    "    def load_and_preprocess_data(self):\n",
    "        \"\"\"Tải và tiền xử lý dữ liệu Vietlott.\"\"\"\n",
    "        logging.info(\"Đang tải dữ liệu...\")\n",
    "        try:\n",
    "            if not os.path.exists(self.config['file_path']):\n",
    "                raise FileNotFoundError(f\"File không tồn tại: {self.config['file_path']}\")\n",
    "\n",
    "            self.df = pd.read_csv(self.config['file_path'], encoding='utf-8')\n",
    "            if 'Ngày' not in self.df.columns or 'Kết Quả' not in self.df.columns:\n",
    "                raise ValueError(\"CSV phải chứa cột 'Ngày' và 'Kết Quả'\")\n",
    "\n",
    "            # Xử lý dữ liệu\n",
    "            self.df['Numbers'] = self.df['Kết Quả'].apply(literal_eval)\n",
    "            self.df['Date'] = pd.to_datetime(self.df['Ngày'], format='%Y-%m-%d')\n",
    "            self.df = self.df.dropna(subset=['Date', 'Numbers']).sort_values('Date')\n",
    "\n",
    "            # Lọc từ 2020\n",
    "            self.df = self.df[self.df['Date'] >= '2020-01-01']\n",
    "            if len(self.df) < 300:\n",
    "                raise ValueError(f\"Dữ liệu chỉ có {len(self.df)} kỳ, cần ít nhất 300 kỳ.\")\n",
    "\n",
    "            self.results = self.df['Numbers'].tolist()\n",
    "            self.compute_statistical_patterns()\n",
    "\n",
    "            # Tính đặc trưng\n",
    "            self.df['OddCount'] = self.df['Numbers'].apply(lambda x: sum(1 for n in x if n % 2 == 1))\n",
    "            self.df['Sum'] = self.df['Numbers'].apply(sum)\n",
    "            self.df['Range'] = self.df['Numbers'].apply(lambda x: max(x) - min(x))\n",
    "            self.df['RecentFreq'] = self.df['Numbers'].apply(lambda x: sum(self.statistical_patterns['recent_frequencies'].get(n, 0) for n in x))\n",
    "            self.df['PairFreq'] = self.df['Numbers'].apply(lambda x: sum(self.statistical_patterns['pair_frequencies'].get(tuple(sorted([x[i], x[j]])), 0) for i in range(5) for j in range(i+1, 6)))\n",
    "\n",
    "            logging.info(f\"Dữ liệu đã tải: {len(self.df)} kỳ\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Lỗi khi tải dữ liệu: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def compute_statistical_patterns(self):\n",
    "        \"\"\"Tính toán mẫu thống kê.\"\"\"\n",
    "        all_numbers = [num for draw in self.results for num in draw]\n",
    "        freq = Counter(all_numbers)\n",
    "        total_draws = len(self.results)\n",
    "        self.statistical_patterns['frequencies'] = {int(k): v for k, v in freq.items()}\n",
    "        self.statistical_patterns['number_probabilities'] = {int(k): v / (total_draws * 6) for k, v in freq.items()}\n",
    "        self.statistical_patterns['hot_numbers'] = sorted(freq, key=freq.get, reverse=True)[:10] or list(range(1, 46))\n",
    "\n",
    "        recent_numbers = [num for draw in self.results[-15:] for num in draw]\n",
    "        recent_freq = Counter(recent_numbers)\n",
    "        self.statistical_patterns['recent_frequencies'] = {int(k): v / 90 for k, v in recent_freq.items()} if recent_numbers else {i: 1/45 for i in range(1, 46)}\n",
    "\n",
    "        pairs = [tuple(sorted([self.results[i][j], self.results[i][k]])) for i in range(len(self.results)) for j in range(5) for k in range(j+1, 6)]\n",
    "        self.statistical_patterns['pair_frequencies'] = {p: v / total_draws for p, v in Counter(pairs).items()}\n",
    "\n",
    "    def get_next_draw_and_date(self, steps_ahead=1):\n",
    "        \"\"\"Tính kỳ quay và ngày quay tiếp theo.\"\"\"\n",
    "        if self.df is None or self.df.empty:\n",
    "            raise ValueError(\"Dữ liệu chưa được tải.\")\n",
    "        logging.info(\"Tính ngày quay tiếp theo...\")\n",
    "\n",
    "        self.df['Draw'] = range(1, len(self.df) + 1)\n",
    "        last_draw = self.df['Draw'].iloc[-1]\n",
    "        last_date = self.df['Date'].iloc[-1]\n",
    "\n",
    "        days = ['Thứ Hai', 'Thứ Ba', 'Thứ Tư', 'Thứ Năm', 'Thứ Sáu', 'Thứ Bảy', 'Chủ Nhật']\n",
    "        logging.info(f\"Ngày cuối: {last_date.strftime('%Y-%m-%d')} ({days[last_date.weekday()]})\")\n",
    "\n",
    "        target_days = [2, 4, 6]  # Thứ Tư, Thứ Sáu, Chủ Nhật\n",
    "        current_date = last_date\n",
    "        for _ in range(steps_ahead):\n",
    "            current_day = current_date.weekday()\n",
    "            days_ahead = min((target - current_day) % 7 for target in target_days if target != current_day)\n",
    "            if days_ahead == 0:\n",
    "                days_ahead = min((target - current_day) % 7 or 7 for target in target_days if target != current_day)\n",
    "            current_date += timedelta(days=days_ahead)\n",
    "\n",
    "        self.next_date = current_date\n",
    "        self.next_draw = last_draw + steps_ahead\n",
    "        logging.info(f\"Kỳ quay tiếp theo: {self.next_draw}, Ngày: {self.next_date.strftime('%Y-%m-%d')}\")\n",
    "        return self.next_draw, self.next_date\n",
    "\n",
    "    def prepare_sequences(self):\n",
    "        \"\"\"Chuẩn bị chuỗi dữ liệu.\"\"\"\n",
    "        logging.info(\"Chuẩn bị chuỗi dữ liệu...\")\n",
    "        sequences = []\n",
    "        targets = []\n",
    "        features = []\n",
    "        for i in range(len(self.results) - self.config['sequence_length']):\n",
    "            seq = self.results[i:i + self.config['sequence_length']]\n",
    "            target = self.results[i + self.config['sequence_length']]\n",
    "            seq_features = [\n",
    "                self.df['OddCount'].iloc[i:i + self.config['sequence_length']].values,\n",
    "                self.df['Sum'].iloc[i:i + self.config['sequence_length']].values,\n",
    "                self.df['Range'].iloc[i:i + self.config['sequence_length']].values,\n",
    "                self.df['RecentFreq'].iloc[i:i + self.config['sequence_length']].values,\n",
    "                self.df['PairFreq'].iloc[i:i + self.config['sequence_length']].values\n",
    "            ]\n",
    "            sequences.append(seq)\n",
    "            targets.append(target)\n",
    "            features.append(np.stack(seq_features, axis=-1))\n",
    "\n",
    "        X = np.array(sequences)\n",
    "        X_features = np.array(features)\n",
    "        y = np.array(targets)\n",
    "\n",
    "        X_scaled = self.scaler.fit_transform(X.reshape(-1, X.shape[-1])).reshape(X.shape)\n",
    "        X_features_scaled = self.feature_scaler.fit_transform(X_features.reshape(-1, X_features.shape[-1])).reshape(X_features.shape)\n",
    "        X = np.concatenate([X_scaled, X_features_scaled], axis=-1)\n",
    "\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(\n",
    "            X, y, test_size=0.2, random_state=RANDOM_SEED, shuffle=False\n",
    "        )\n",
    "\n",
    "        last_sequence = np.array(self.results[-self.config['sequence_length']:])\n",
    "        last_features = np.stack([\n",
    "            self.df['OddCount'].iloc[-self.config['sequence_length']:].values,\n",
    "            self.df['Sum'].iloc[-self.config['sequence_length']:].values,\n",
    "            self.df['Range'].iloc[-self.config['sequence_length']:].values,\n",
    "            self.df['RecentFreq'].iloc[-self.config['sequence_length']:].values,\n",
    "            self.df['PairFreq'].iloc[-self.config['sequence_length']:].values\n",
    "        ], axis=-1)\n",
    "        last_sequence_scaled = self.scaler.transform(last_sequence.reshape(-1, 6)).reshape(1, self.config['sequence_length'], 6)\n",
    "        last_features_scaled = self.feature_scaler.transform(last_features.reshape(-1, 5)).reshape(1, self.config['sequence_length'], 5)\n",
    "        self.last_sequence = np.concatenate([last_sequence_scaled, last_features_scaled], axis=-1)\n",
    "\n",
    "        logging.info(f\"Tập huấn luyện: {self.X_train.shape}, Tập kiểm tra: {self.X_test.shape}\")\n",
    "\n",
    "    def build_tcn_model(self):\n",
    "        \"\"\"Xây dựng mô hình TCN.\"\"\"\n",
    "        model = Sequential([\n",
    "            Conv1D(self.config['tcn_filters'][0], kernel_size=3, activation='relu', input_shape=(self.config['sequence_length'], 11), kernel_regularizer=l2(0.01)),\n",
    "            BatchNormalization(),\n",
    "            Dropout(self.config['dropout_rate']),\n",
    "            Conv1D(self.config['tcn_filters'][1], kernel_size=3, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "            BatchNormalization(),\n",
    "            Dropout(self.config['dropout_rate']),\n",
    "            Conv1D(self.config['tcn_filters'][2], kernel_size=3, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "            BatchNormalization(),\n",
    "            Dropout(self.config['dropout_rate']),\n",
    "            Flatten(),\n",
    "            Dense(45, activation='sigmoid')\n",
    "        ])\n",
    "        model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=self.config['learning_rate']),\n",
    "                      loss='binary_crossentropy', metrics=[Precision(top_k=6, name='precision_at_k')])\n",
    "        return model\n",
    "\n",
    "    def build_lstm_model(self):\n",
    "        \"\"\"Xây dựng mô hình LSTM.\"\"\"\n",
    "        model = Sequential([\n",
    "            LSTM(self.config['lstm_units'][0], input_shape=(self.config['sequence_length'], 11), return_sequences=True),\n",
    "            BatchNormalization(),\n",
    "            Dropout(self.config['dropout_rate']),\n",
    "            LSTM(self.config['lstm_units'][1]),\n",
    "            BatchNormalization(),\n",
    "            Dropout(self.config['dropout_rate']),\n",
    "            Dense(45, activation='sigmoid')\n",
    "        ])\n",
    "        model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=self.config['learning_rate']),\n",
    "                      loss='binary_crossentropy', metrics=[Precision(top_k=6, name='precision_at_k')])\n",
    "        return model\n",
    "\n",
    "    def build_gru_model(self):\n",
    "        \"\"\"Xây dựng mô hình GRU.\"\"\"\n",
    "        model = Sequential([\n",
    "            GRU(self.config['gru_units'][0], input_shape=(self.config['sequence_length'], 11), return_sequences=True),\n",
    "            BatchNormalization(),\n",
    "            Dropout(self.config['dropout_rate']),\n",
    "            GRU(self.config['gru_units'][1]),\n",
    "            BatchNormalization(),\n",
    "            Dropout(self.config['dropout_rate']),\n",
    "            Dense(45, activation='sigmoid')\n",
    "        ])\n",
    "        model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=self.config['learning_rate']),\n",
    "                      loss='binary_crossentropy', metrics=[Precision(top_k=6, name='precision_at_k')])\n",
    "        return model\n",
    "\n",
    "    def build_transformer_model(self):\n",
    "        \"\"\"Xây dựng mô hình Transformer.\"\"\"\n",
    "        inputs = tf.keras.Input(shape=(self.config['sequence_length'], 11))\n",
    "        x = MultiHeadAttention(num_heads=self.config['transformer_heads'], key_dim=64)(inputs, inputs)\n",
    "        x = LayerNormalization(epsilon=1e-6)(x + inputs)\n",
    "        x = Dense(128, activation='relu')(x)\n",
    "        x = Dense(11)(x)\n",
    "        x = LayerNormalization(epsilon=1e-6)(x + inputs)\n",
    "        x = Flatten()(x)\n",
    "        outputs = Dense(45, activation='sigmoid')(x)\n",
    "        model = tf.keras.Model(inputs, outputs)\n",
    "        model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=self.config['learning_rate']),\n",
    "                      loss='binary_crossentropy', metrics=[Precision(top_k=6, name='precision_at_k')])\n",
    "        return model\n",
    "\n",
    "    def build_rf_model(self):\n",
    "        \"\"\"Xây dựng mô hình Random Forest.\"\"\"\n",
    "        return RandomForestClassifier(n_estimators=self.config['rf_estimators'], random_state=RANDOM_SEED)\n",
    "\n",
    "    def evaluate_model(self, model, model_name, is_rf=False):\n",
    "        \"\"\"Đánh giá mô hình.\"\"\"\n",
    "        if is_rf:\n",
    "            X_test_rf = self.X_test.reshape(self.X_test.shape[0], -1)\n",
    "            pred_probs = np.array([model.predict_proba(X_test_rf)[i][:, 1] for i in range(45)]).T\n",
    "        else:\n",
    "            pred_probs = model.predict(self.X_test, verbose=0)\n",
    "\n",
    "        pred = [sorted(np.argsort(p)[-6:][::-1] + 1) for p in pred_probs]\n",
    "        pred = [self.adjust_prediction(p) for p in pred]\n",
    "\n",
    "        y_true = self.y_test.astype(int)\n",
    "        matches = [len(set(p).intersection(set(t))) for p, t in zip(pred, y_true)]\n",
    "        match_3 = sum(1 for m in matches if m >= 3) / len(matches) if matches else 0\n",
    "        match_4_plus = sum(1 for m in matches if m >= 4) / len(matches) if matches else 0\n",
    "        logging.info(f\"{model_name} - Match 3+: {match_3:.3f}, Match 4+: {match_4_plus:.3f}\")\n",
    "        return pred_probs\n",
    "\n",
    "    def adjust_prediction(self, pred):\n",
    "        \"\"\"Điều chỉnh dự đoán.\"\"\"\n",
    "        pred = sorted(list(set(pred)))\n",
    "        if len(pred) < 6:\n",
    "            pred.extend(random.sample(self.statistical_patterns['hot_numbers'], 6 - len(pred)))\n",
    "\n",
    "        if sum(pred) < 130 or sum(pred) > 140:\n",
    "            pred = pred[:5] + [random.choice(self.statistical_patterns['hot_numbers'])]\n",
    "        if sum(1 for n in pred if n % 2 == 1) not in [3, 4]:\n",
    "            odd_count = sum(1 for n in pred if n % 2 == 1)\n",
    "            candidates = [n for n in self.statistical_patterns['hot_numbers'] if n % 2 == (1 if odd_count < 3 else 0)]\n",
    "            pred = pred[:5] + [random.choice(candidates or self.statistical_patterns['hot_numbers'])]\n",
    "        if not (any(1 <= n <= 15 for n in pred) and any(16 <= n <= 30 for n in pred) and any(31 <= n <= 45 for n in pred)):\n",
    "            pred = pred[:3] + [\n",
    "                random.choice([n for n in self.statistical_patterns['hot_numbers'] if 1 <= n <= 15] or range(1, 16)),\n",
    "                random.choice([n for n in self.statistical_patterns['hot_numbers'] if 16 <= n <= 30] or range(16, 31)),\n",
    "                random.choice([n for n in self.statistical_patterns['hot_numbers'] if 31 <= n <= 45] or range(31, 46))\n",
    "            ]\n",
    "        return sorted(pred[:6])\n",
    "\n",
    "    def train_models(self):\n",
    "        \"\"\"Huấn luyện các mô hình.\"\"\"\n",
    "        logging.info(\"Huấn luyện mô hình...\")\n",
    "        callbacks = [\n",
    "            EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True),\n",
    "            ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=7),\n",
    "            PrintTrainingMetrics()\n",
    "        ]\n",
    "        y_train_bin = np.array([[1 if j+1 in draw else 0 for j in range(45)] for draw in self.y_train])\n",
    "        y_test_bin = np.array([[1 if j+1 in draw else 0 for j in range(45)] for draw in self.y_test])\n",
    "\n",
    "        models = {}\n",
    "        probs = {}\n",
    "        for name, builder in [\n",
    "            ('tcn', self.build_tcn_model),\n",
    "            ('lstm', self.build_lstm_model),\n",
    "            ('gru', self.build_gru_model),\n",
    "            ('transformer', self.build_transformer_model)\n",
    "        ]:\n",
    "            logging.info(f\"Huấn luyện {name}...\")\n",
    "            model = builder()\n",
    "            model.fit(self.X_train, y_train_bin, validation_data=(self.X_test, y_test_bin),\n",
    "                      epochs=self.config['epochs'], batch_size=self.config['batch_size'], callbacks=callbacks, verbose=0)\n",
    "            probs[name] = self.evaluate_model(model, name)\n",
    "            models[name] = model\n",
    "\n",
    "        logging.info(\"Huấn luyện Random Forest...\")\n",
    "        rf_model = self.build_rf_model()\n",
    "        X_train_rf = self.X_train.reshape(self.X_train.shape[0], -1)\n",
    "        rf_model.fit(X_train_rf, y_train_bin)\n",
    "        probs['rf'] = self.evaluate_model(rf_model, 'rf', is_rf=True)\n",
    "        models['rf'] = rf_model\n",
    "\n",
    "        return models, probs\n",
    "\n",
    "    def predict(self):\n",
    "        \"\"\"Dự đoán bộ số.\"\"\"\n",
    "        logging.info(\"Dự đoán bộ số...\")\n",
    "        models, probs = self.train_models()\n",
    "\n",
    "        model_probs = {}\n",
    "        for name in ['tcn', 'lstm', 'gru', 'transformer']:\n",
    "            model_probs[name] = models[name].predict(self.last_sequence, verbose=0)[0]\n",
    "        last_sequence_rf = self.last_sequence.reshape(1, -1)\n",
    "        model_probs['rf'] = np.array([models['rf'].predict_proba(last_sequence_rf)[i][:, 1][0] for i in range(45)])\n",
    "        hist_probs = np.array([self.statistical_patterns['number_probabilities'].get(i+1, 0) for i in range(45)])\n",
    "        recent_probs = np.array([self.statistical_patterns['recent_frequencies'].get(i+1, 0) for i in range(45)])\n",
    "\n",
    "        final_probs = (0.25 * model_probs['tcn'] + 0.25 * model_probs['lstm'] + 0.2 * model_probs['gru'] +\n",
    "                       0.2 * model_probs['transformer'] + 0.1 * model_probs['rf'] +\n",
    "                       0.15 * 0.7 * hist_probs + 0.15 * 0.3 * recent_probs)\n",
    "        final_probs /= final_probs.sum()\n",
    "\n",
    "        predictions = {}\n",
    "        for name in model_probs:\n",
    "            pred = sorted(np.argsort(model_probs[name])[-6:][::-1] + 1)\n",
    "            predictions[name] = self.adjust_prediction(pred)\n",
    "\n",
    "        freq_nums = sorted(self.statistical_patterns['recent_frequencies'], key=self.statistical_patterns['recent_frequencies'].get, reverse=True)[:6]\n",
    "        predictions['frequency'] = self.adjust_prediction(freq_nums)\n",
    "\n",
    "        ensemble_nums = sorted(np.argsort(final_probs)[-6:][::-1] + 1)\n",
    "        predictions['ensemble'] = self.adjust_prediction(ensemble_nums)\n",
    "\n",
    "        all_numbers = [num for pred in predictions.values() for num in pred]\n",
    "        number_counts = Counter(all_numbers)\n",
    "        common_numbers = sorted([num for num, count in number_counts.items() if count >= 2])\n",
    "\n",
    "        final_prediction = common_numbers[:6]\n",
    "        if len(final_prediction) < 6:\n",
    "            remaining = [n for n in self.statistical_patterns['hot_numbers'] if n not in final_prediction]\n",
    "            final_prediction.extend(random.sample(remaining, 6 - len(final_prediction)))\n",
    "        final_prediction = sorted(final_prediction[:6])\n",
    "\n",
    "        logging.info(f\"Dự đoán cuối cùng cho kỳ {self.next_draw} ({self.next_date.strftime('%Y-%m-%d')}): {final_prediction}\")\n",
    "        return {\n",
    "            'final_prediction': final_prediction,\n",
    "            'common_numbers': common_numbers,\n",
    "            'predictions': predictions,\n",
    "            'draw': self.next_draw,\n",
    "            'date': self.next_date\n",
    "        }\n",
    "\n",
    "    def run(self, steps_ahead=1):\n",
    "        \"\"\"Chạy quy trình dự đoán.\"\"\"\n",
    "        logging.info(\"Bắt đầu dự đoán...\")\n",
    "        try:\n",
    "            self.load_and_preprocess_data()\n",
    "            self.get_next_draw_and_date(steps_ahead)\n",
    "            self.prepare_sequences()\n",
    "            results = self.predict()\n",
    "            logging.info(f\"Hoàn tất dự đoán cho kỳ {self.next_draw}\")\n",
    "            return results\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Lỗi: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    if not os.path.exists(CONFIG['file_path']):\n",
    "        print(f\"Lỗi: File {CONFIG['file_path']} không tồn tại!\")\n",
    "    else:\n",
    "        predictor = VietlottPredictor()\n",
    "        try:\n",
    "            results = predictor.run(steps_ahead=2)\n",
    "            print(f\"\\nDỰ ĐOÁN CHO KỲ {results['draw']} ({results['date'].strftime('%Y-%m-%d')}):\")\n",
    "            print(f\"Số dự đoán: {results['final_prediction']}\")\n",
    "            print(f\"Số chung: {results['common_numbers']}\")\n",
    "            print(\"\\nDỰ ĐOÁN TỪ MÔ HÌNH:\")\n",
    "            for model, pred in results['predictions'].items():\n",
    "                print(f\"{model.capitalize()}: {pred}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Lỗi: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fcdee85",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8b49b5f3",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af10ed6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb58b631",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
