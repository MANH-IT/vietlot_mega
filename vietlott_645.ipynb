{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2174711d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vietlott_env\\Scripts\\activate\n",
    "# git add vietlott_645.ipynb\n",
    "# git commit -m \"Cập nhật mô hình 6/45\"\n",
    "# git push origin master"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38dee3a4",
   "metadata": {},
   "source": [
    "# Cài đặt thư viện "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ce83c95f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in e:\\python3_8_64bit\\lib\\site-packages (2.0.3)\n",
      "Requirement already satisfied: deap in e:\\python3_8_64bit\\lib\\site-packages (1.4.3)\n",
      "Requirement already satisfied: requests in e:\\python3_8_64bit\\lib\\site-packages (2.32.3)\n",
      "Requirement already satisfied: bayesian-optimization in e:\\python3_8_64bit\\lib\\site-packages (1.4.3)\n",
      "Requirement already satisfied: beautifulsoup4 in e:\\python3_8_64bit\\lib\\site-packages (4.13.4)\n",
      "Requirement already satisfied: seaborn in e:\\python3_8_64bit\\lib\\site-packages (0.13.2)\n",
      "Requirement already satisfied: selenium in e:\\python3_8_64bit\\lib\\site-packages (4.27.1)\n",
      "Requirement already satisfied: matplotlib in e:\\python3_8_64bit\\lib\\site-packages (3.7.5)\n",
      "Requirement already satisfied: sklearn in e:\\python3_8_64bit\\lib\\site-packages (0.0)\n",
      "Requirement already satisfied: tensorflow in e:\\python3_8_64bit\\lib\\site-packages (2.12.0)\n",
      "Requirement already satisfied: numpy in e:\\python3_8_64bit\\lib\\site-packages (1.23.5)\n",
      "Requirement already satisfied: scikit-learn in e:\\python3_8_64bit\\lib\\site-packages (1.3.2)\n",
      "Requirement already satisfied: xgboost in e:\\python3_8_64bit\\lib\\site-packages (2.1.4)\n",
      "Requirement already satisfied: lightgbm in e:\\python3_8_64bit\\lib\\site-packages (4.6.0)\n",
      "Requirement already satisfied: tensorflow-addons in e:\\python3_8_64bit\\lib\\site-packages (0.21.0)\n",
      "Requirement already satisfied: optuna in e:\\python3_8_64bit\\lib\\site-packages (4.3.0)\n",
      "Requirement already satisfied: imbalanced-learn in e:\\python3_8_64bit\\lib\\site-packages (0.12.4)\n",
      "Requirement already satisfied: torch in e:\\python3_8_64bit\\lib\\site-packages (2.4.1)\n",
      "Requirement already satisfied: schedule in e:\\python3_8_64bit\\lib\\site-packages (1.2.2)\n",
      "Requirement already satisfied: apscheduler in e:\\python3_8_64bit\\lib\\site-packages (3.11.0)\n",
      "Requirement already satisfied: pyarrow in e:\\python3_8_64bit\\lib\\site-packages (17.0.0)\n",
      "Requirement already satisfied: joblib in e:\\python3_8_64bit\\lib\\site-packages (1.4.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in e:\\python3_8_64bit\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\nitro 5\\appdata\\roaming\\python\\python38\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata>=2022.1 in e:\\python3_8_64bit\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\nitro 5\\appdata\\roaming\\python\\python38\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in e:\\python3_8_64bit\\lib\\site-packages (from requests) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in e:\\python3_8_64bit\\lib\\site-packages (from requests) (2025.4.26)\n",
      "Requirement already satisfied: idna<4,>=2.5 in e:\\python3_8_64bit\\lib\\site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in e:\\python3_8_64bit\\lib\\site-packages (from requests) (3.4.2)\n",
      "Requirement already satisfied: colorama>=0.4.6 in c:\\users\\nitro 5\\appdata\\roaming\\python\\python38\\site-packages (from bayesian-optimization) (0.4.6)\n",
      "Requirement already satisfied: scipy>=1.0.0 in e:\\python3_8_64bit\\lib\\site-packages (from bayesian-optimization) (1.10.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in e:\\python3_8_64bit\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\users\\nitro 5\\appdata\\roaming\\python\\python38\\site-packages (from beautifulsoup4) (4.13.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in e:\\python3_8_64bit\\lib\\site-packages (from beautifulsoup4) (2.7)\n",
      "Requirement already satisfied: pillow>=6.2.0 in e:\\python3_8_64bit\\lib\\site-packages (from matplotlib) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in e:\\python3_8_64bit\\lib\\site-packages (from matplotlib) (3.1.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\nitro 5\\appdata\\roaming\\python\\python38\\site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in e:\\python3_8_64bit\\lib\\site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in e:\\python3_8_64bit\\lib\\site-packages (from matplotlib) (6.4.5)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in e:\\python3_8_64bit\\lib\\site-packages (from matplotlib) (1.1.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in e:\\python3_8_64bit\\lib\\site-packages (from matplotlib) (4.57.0)\n",
      "Requirement already satisfied: cycler>=0.10 in e:\\python3_8_64bit\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\nitro 5\\appdata\\roaming\\python\\python38\\site-packages (from importlib-resources>=3.2.0->matplotlib) (3.20.2)\n",
      "Requirement already satisfied: trio~=0.17 in e:\\python3_8_64bit\\lib\\site-packages (from selenium) (0.27.0)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in e:\\python3_8_64bit\\lib\\site-packages (from selenium) (0.12.2)\n",
      "Requirement already satisfied: websocket-client~=1.8 in e:\\python3_8_64bit\\lib\\site-packages (from selenium) (1.8.0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in e:\\python3_8_64bit\\lib\\site-packages (from trio~=0.17->selenium) (1.3.1)\n",
      "Requirement already satisfied: cffi>=1.14 in e:\\python3_8_64bit\\lib\\site-packages (from trio~=0.17->selenium) (1.17.1)\n",
      "Requirement already satisfied: outcome in e:\\python3_8_64bit\\lib\\site-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
      "Requirement already satisfied: exceptiongroup in e:\\python3_8_64bit\\lib\\site-packages (from trio~=0.17->selenium) (1.3.0)\n",
      "Requirement already satisfied: attrs>=23.2.0 in e:\\python3_8_64bit\\lib\\site-packages (from trio~=0.17->selenium) (25.3.0)\n",
      "Requirement already satisfied: sortedcontainers in e:\\python3_8_64bit\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: pycparser in e:\\python3_8_64bit\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.22)\n",
      "Requirement already satisfied: wsproto>=0.14 in e:\\python3_8_64bit\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in e:\\python3_8_64bit\\lib\\site-packages (from urllib3<3,>=1.21.1->requests) (1.7.1)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in e:\\python3_8_64bit\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.16.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.12.0 in e:\\python3_8_64bit\\lib\\site-packages (from tensorflow) (2.12.0)\n",
      "Requirement already satisfied: jax>=0.3.15 in e:\\python3_8_64bit\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (0.4.13)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in e:\\python3_8_64bit\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.70.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in e:\\python3_8_64bit\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (2.12.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in e:\\python3_8_64bit\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (4.25.8)\n",
      "Requirement already satisfied: h5py>=2.9.0 in e:\\python3_8_64bit\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (3.11.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in e:\\python3_8_64bit\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in e:\\python3_8_64bit\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: libclang>=13.0.0 in e:\\python3_8_64bit\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in e:\\python3_8_64bit\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in e:\\python3_8_64bit\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: keras<2.13,>=2.12.0 in e:\\python3_8_64bit\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (2.12.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in e:\\python3_8_64bit\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (25.2.10)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in e:\\python3_8_64bit\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in e:\\python3_8_64bit\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in e:\\python3_8_64bit\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in e:\\python3_8_64bit\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: setuptools in e:\\python3_8_64bit\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (56.0.0)\n",
      "Requirement already satisfied: tensorboard<2.13,>=2.12 in e:\\python3_8_64bit\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (2.12.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in e:\\python3_8_64bit\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.12.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: ml-dtypes>=0.1.0 in e:\\python3_8_64bit\\lib\\site-packages (from jax>=0.3.15->tensorflow-intel==2.12.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.6 in c:\\users\\nitro 5\\appdata\\roaming\\python\\python38\\site-packages (from jax>=0.3.15->tensorflow-intel==2.12.0->tensorflow) (8.5.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in e:\\python3_8_64bit\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.40.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in e:\\python3_8_64bit\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in e:\\python3_8_64bit\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in e:\\python3_8_64bit\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (3.0.6)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in e:\\python3_8_64bit\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in e:\\python3_8_64bit\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (4.9.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in e:\\python3_8_64bit\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (0.4.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in e:\\python3_8_64bit\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (5.5.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in e:\\python3_8_64bit\\lib\\site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.0.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in e:\\python3_8_64bit\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in e:\\python3_8_64bit\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (3.2.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in e:\\python3_8_64bit\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.1.5)\n",
      "Requirement already satisfied: typeguard<3.0.0,>=2.7 in e:\\python3_8_64bit\\lib\\site-packages (from tensorflow-addons) (2.13.3)\n",
      "Requirement already satisfied: PyYAML in e:\\python3_8_64bit\\lib\\site-packages (from optuna) (6.0.2)\n",
      "Requirement already satisfied: tqdm in e:\\python3_8_64bit\\lib\\site-packages (from optuna) (4.67.1)\n",
      "Requirement already satisfied: colorlog in e:\\python3_8_64bit\\lib\\site-packages (from optuna) (6.9.0)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.2 in e:\\python3_8_64bit\\lib\\site-packages (from optuna) (2.0.41)\n",
      "Requirement already satisfied: alembic>=1.5.0 in e:\\python3_8_64bit\\lib\\site-packages (from optuna) (1.14.1)\n",
      "Requirement already satisfied: Mako in e:\\python3_8_64bit\\lib\\site-packages (from alembic>=1.5.0->optuna) (1.3.10)\n",
      "Requirement already satisfied: greenlet>=1 in e:\\python3_8_64bit\\lib\\site-packages (from sqlalchemy>=1.4.2->optuna) (3.1.1)\n",
      "Requirement already satisfied: filelock in e:\\python3_8_64bit\\lib\\site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: fsspec in e:\\python3_8_64bit\\lib\\site-packages (from torch) (2025.3.0)\n",
      "Requirement already satisfied: jinja2 in e:\\python3_8_64bit\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: networkx in e:\\python3_8_64bit\\lib\\site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: sympy in e:\\python3_8_64bit\\lib\\site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: tzlocal>=3.0 in e:\\python3_8_64bit\\lib\\site-packages (from apscheduler) (5.2)\n",
      "Requirement already satisfied: backports.zoneinfo in e:\\python3_8_64bit\\lib\\site-packages (from apscheduler) (0.2.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in e:\\python3_8_64bit\\lib\\site-packages (from sympy->torch) (1.3.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.1.1; however, version 25.0.1 is available.\n",
      "You should consider upgrading via the 'e:\\python3_8_64bit\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "! pip install pandas deap requests bayesian-optimization beautifulsoup4 seaborn selenium matplotlib sklearn tensorflow numpy scikit-learn xgboost lightgbm tensorflow-addons optuna imbalanced-learn torch schedule apscheduler pyarrow joblib\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b93681c",
   "metadata": {},
   "source": [
    "# Xử lý data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "049c4ad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thông tin dữ liệu:\n",
      "- Số cột: 3\n",
      "- Tên cột: ['Ngày Mở Thưởng', 'Kết Quả', 'Giải Jackpot']\n",
      "- Số dòng: 1356\n",
      "- Dữ liệu mẫu (5 dòng đầu):\n",
      "   Ngày Mở Thưởng            Kết Quả    Giải Jackpot\n",
      "0  T4, 28/05/2025  17 22 23 28 31 41  29.736.250.000\n",
      "1  CN, 25/05/2025  05 14 23 24 28 44  25.290.182.500\n",
      "2  T6, 23/05/2025  02 04 15 16 29 43  23.051.056.000\n",
      "3  T4, 21/05/2025  02 13 14 21 24 30  20.908.114.000\n",
      "4  CN, 18/05/2025  06 07 17 27 30 42  18.835.213.500\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Tham số hóa đường dẫn\n",
    "DATA_DIR = \"data_645\"\n",
    "FILE_NAME = \"E:/vietlot_mega\\data_645/vietlott_645_filtered.csv\"\n",
    "FILE_PATH = os.path.join(DATA_DIR, FILE_NAME)\n",
    "\n",
    "# Kiểm tra file tồn tại\n",
    "if not os.path.exists(FILE_PATH):\n",
    "    raise FileNotFoundError(f\"Không tìm thấy file: {FILE_PATH}\")\n",
    "\n",
    "# Đọc dữ liệu\n",
    "try:\n",
    "    df = pd.read_csv(FILE_PATH, sep=\"\\t\")\n",
    "except Exception as e:\n",
    "    raise Exception(f\"Lỗi khi đọc file {FILE_PATH}: {e}\")\n",
    "\n",
    "# Kiểm tra cột\n",
    "expected_columns = ['Ngày Mở Thưởng', 'Kết Quả', 'Giải Jackpot']\n",
    "if not all(col in df.columns for col in expected_columns):\n",
    "    raise ValueError(f\"Dữ liệu thiếu cột: {set(expected_columns) - set(df.columns)}\")\n",
    "\n",
    "# Kiểm tra dữ liệu thiếu\n",
    "if df.isna().any().any():\n",
    "    print(\"Cảnh báo: Dữ liệu có giá trị thiếu:\")\n",
    "    print(df.isna().sum())\n",
    "\n",
    "# In thông tin cơ bản\n",
    "print(\"Thông tin dữ liệu:\")\n",
    "print(f\"- Số cột: {len(df.columns)}\")\n",
    "print(f\"- Tên cột: {list(df.columns)}\")\n",
    "print(f\"- Số dòng: {len(df)}\")\n",
    "print(f\"- Dữ liệu mẫu (5 dòng đầu):\\n{df.head()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9b462334",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cảnh báo: Có giá trị Jackpot không hợp lệ:\n",
      "     Ngày Mở Thưởng  Giải Jackpot\n",
      "0        2025-05-28           NaN\n",
      "1        2025-05-25           NaN\n",
      "2        2025-05-23           NaN\n",
      "3        2025-05-21           NaN\n",
      "4        2025-05-18           NaN\n",
      "...             ...           ...\n",
      "1351     2016-08-05           NaN\n",
      "1352     2016-08-03           NaN\n",
      "1353     2016-07-31           NaN\n",
      "1354     2016-07-29           NaN\n",
      "1355     2016-07-27           NaN\n",
      "\n",
      "[1356 rows x 2 columns]\n",
      "Dữ liệu sau khi xử lý (5 dòng đầu):\n",
      "        Ngày                   Kết Quả  Jackpot\n",
      "0 2025-05-28  [17, 22, 23, 28, 31, 41]      NaN\n",
      "1 2025-05-25   [5, 14, 23, 24, 28, 44]      NaN\n",
      "2 2025-05-23    [2, 4, 15, 16, 29, 43]      NaN\n",
      "3 2025-05-21   [2, 13, 14, 21, 24, 30]      NaN\n",
      "4 2025-05-18    [6, 7, 17, 27, 30, 42]      NaN\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Tham số hóa đường dẫn\n",
    "DATA_DIR = \"data_645\"\n",
    "FILE_NAME = \"vietlott_645_filtered.csv\"\n",
    "FILE_PATH = os.path.join(DATA_DIR, FILE_NAME)\n",
    "\n",
    "# Hàm kiểm tra tính hợp lệ của kết quả\n",
    "def validate_result(result):\n",
    "    try:\n",
    "        if len(result) != 6:\n",
    "            return False, \"Phải có đúng 6 số\"\n",
    "        if not all(isinstance(x, int) and 1 <= x <= 45 for x in result):\n",
    "            return False, \"Số phải trong khoảng 1-45\"\n",
    "        return True, \"\"\n",
    "    except:\n",
    "        return False, \"Định dạng không hợp lệ\"\n",
    "\n",
    "# Đọc dữ liệu\n",
    "try:\n",
    "    df = pd.read_csv(FILE_PATH, sep=\"\\t\", encoding=\"utf-8\")\n",
    "except Exception as e:\n",
    "    raise Exception(f\"Lỗi khi đọc file {FILE_PATH}: {e}\")\n",
    "\n",
    "# Kiểm tra và xử lý cột\n",
    "if 'Kết Quả' in df.columns and 'Ngày Mở Thưởng' in df.columns and 'Giải Jackpot' in df.columns:\n",
    "    # Chuyển đổi Kết Quả từ chuỗi phân cách bởi khoảng trắng sang danh sách số nguyên\n",
    "    df['Kết Quả'] = df['Kết Quả'].apply(lambda x: [int(i) for i in x.split()] if isinstance(x, str) else x)\n",
    "    \n",
    "    # Kiểm tra tính hợp lệ của Kết Quả\n",
    "    df['Valid_Result'] = df['Kết Quả'].apply(validate_result)\n",
    "    invalid_results = df[~df['Valid_Result'].apply(lambda x: x[0])]\n",
    "    if not invalid_results.empty:\n",
    "        print(\"Cảnh báo: Phát hiện kết quả không hợp lệ:\")\n",
    "        print(invalid_results[['Ngày Mở Thưởng', 'Kết Quả', 'Valid_Result']])\n",
    "    \n",
    "    # Xử lý cột Ngày: Loại bỏ tiền tố ngày trong tuần (CN, T6, T4) và chuyển đổi định dạng\n",
    "    try:\n",
    "        # Tách phần ngày (bỏ tiền tố như CN, T6, T4)\n",
    "        df['Ngày Mở Thưởng'] = df['Ngày Mở Thưởng'].str.split(',').str[-1].str.strip()\n",
    "        # Chuyển đổi sang định dạng datetime\n",
    "        df['Ngày Mở Thưởng'] = pd.to_datetime(df['Ngày Mở Thưởng'], format='%d/%m/%Y', dayfirst=True)\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Lỗi khi chuyển đổi cột Ngày: {e}\")\n",
    "    \n",
    "    # Kiểm tra Jackpot\n",
    "    df['Giải Jackpot'] = pd.to_numeric(df['Giải Jackpot'], errors='coerce')\n",
    "    if df['Giải Jackpot'].isna().any():\n",
    "        print(\"Cảnh báo: Có giá trị Jackpot không hợp lệ:\")\n",
    "        print(df[df['Giải Jackpot'].isna()][['Ngày Mở Thưởng', 'Giải Jackpot']])\n",
    "    \n",
    "    # Đổi tên cột cho thống nhất\n",
    "    df = df.rename(columns={'Ngày Mở Thưởng': 'Ngày', 'Giải Jackpot': 'Jackpot'})\n",
    "    \n",
    "    # In dữ liệu mẫu\n",
    "    print(\"Dữ liệu sau khi xử lý (5 dòng đầu):\")\n",
    "    print(df[['Ngày', 'Kết Quả', 'Jackpot']].head())\n",
    "else:\n",
    "    raise ValueError(\"Dữ liệu thiếu cột cần thiết\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6c7538b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Đã ghi file thành công: vietlott_645_clean.csv\n"
     ]
    }
   ],
   "source": [
    "df.to_csv(r\"E:/vietlot_mega/data_645/vietlott_645_clean.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "print(\"✅ Đã ghi file thành công: vietlott_645_clean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dcd94812",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NITRO 5\\AppData\\Local\\Temp\\ipykernel_18208\\3745541686.py:23: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.barplot(x=freq.index, y=freq.values, palette='viridis')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 5 cặp số xuất hiện cùng nhau nhiều nhất:\n",
      "     Cặp số  Tần suất  Tần suất (%)\n",
      "0  (10, 22)        34      2.507375\n",
      "1  (13, 20)        34      2.507375\n",
      "2   (7, 44)        33      2.433628\n",
      "3   (4, 37)        33      2.433628\n",
      "4  (19, 24)        32      2.359882\n",
      "\n",
      "Top 5 bộ ba số xuất hiện cùng nhau nhiều nhất:\n",
      "       Bộ ba số  Tần suất  Tần suất (%)\n",
      "0  (11, 26, 28)         9      0.663717\n",
      "1  (10, 22, 36)         9      0.663717\n",
      "2    (1, 7, 16)         9      0.663717\n",
      "3  (25, 35, 39)         8      0.589971\n",
      "4  (10, 22, 43)         8      0.589971\n",
      "\n",
      "Tần suất tăng/giảm Jackpot:\n",
      "Trend\n",
      "Không đổi    1356\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Giá trị tăng trung bình: nan tỷ VND\n",
      "Giá trị giảm trung bình: nan tỷ VND\n",
      "\n",
      "Phân tích chu kỳ Jackpot:\n",
      "- Số chu kỳ: 1\n",
      "- Độ dài chu kỳ trung bình: 1356.00 kỳ\n",
      "- Độ dài chu kỳ tối đa: 1356 kỳ\n",
      "- Độ dài chu kỳ tối thiểu: 1356 kỳ\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "from itertools import combinations\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Tham số hóa đường dẫn lưu biểu đồ\n",
    "OUTPUT_DIR = \"plots\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Kiểm tra tính hợp lệ của Kết Quả\n",
    "if 'Valid_Result' not in df.columns:\n",
    "    df['Valid_Result'] = df['Kết Quả'].apply(validate_result)\n",
    "invalid_results = df[~df['Valid_Result'].apply(lambda x: x[0])]\n",
    "if not invalid_results.empty:\n",
    "    raise ValueError(\"Dữ liệu chứa kết quả không hợp lệ, vui lòng kiểm tra.\")\n",
    "\n",
    "# 1. Phân tích tần suất số\n",
    "plt.figure(figsize=(15, 6))\n",
    "all_numbers = np.concatenate(df['Kết Quả'].values)\n",
    "freq = pd.Series(all_numbers).value_counts().sort_index()\n",
    "sns.barplot(x=freq.index, y=freq.values, palette='viridis')\n",
    "plt.title('Tần suất xuất hiện của các số (1-45)', fontsize=14)\n",
    "plt.xlabel('Số', fontsize=12)\n",
    "plt.ylabel('Tần suất', fontsize=12)\n",
    "plt.xticks(np.arange(1, 46, 1), rotation=45, fontsize=10)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUTPUT_DIR, 'number_frequency.png'), dpi=300)\n",
    "plt.close()\n",
    "\n",
    "# 2. Phân tích cặp số và bộ ba số\n",
    "pair_counts = Counter()\n",
    "triple_counts = Counter()\n",
    "for result in df['Kết Quả']:\n",
    "    pairs = list(combinations(sorted(result), 2))\n",
    "    pair_counts.update(pairs)\n",
    "    triples = list(combinations(sorted(result), 3))\n",
    "    triple_counts.update(triples)\n",
    "\n",
    "# Chuẩn hóa tần suất\n",
    "num_draws = len(df)\n",
    "top_pairs = pd.DataFrame(pair_counts.most_common(5), columns=['Cặp số', 'Tần suất'])\n",
    "top_pairs['Tần suất (%)'] = top_pairs['Tần suất'] / num_draws * 100\n",
    "print(\"\\nTop 5 cặp số xuất hiện cùng nhau nhiều nhất:\")\n",
    "print(top_pairs[['Cặp số', 'Tần suất', 'Tần suất (%)']])\n",
    "\n",
    "top_triples = pd.DataFrame(triple_counts.most_common(5), columns=['Bộ ba số', 'Tần suất'])\n",
    "top_triples['Tần suất (%)'] = top_triples['Tần suất'] / num_draws * 100\n",
    "print(\"\\nTop 5 bộ ba số xuất hiện cùng nhau nhiều nhất:\")\n",
    "print(top_triples[['Bộ ba số', 'Tần suất', 'Tần suất (%)']])\n",
    "\n",
    "# 3. Phân tích xu hướng Jackpot\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(df['Ngày'], df['Jackpot'] / 1e9, label='Jackpot (tỷ VND)', color='blue')\n",
    "plt.title('Xu hướng giá trị Jackpot theo thời gian', fontsize=14)\n",
    "plt.xlabel('Ngày', fontsize=12)\n",
    "plt.ylabel('Jackpot (tỷ VND)', fontsize=12)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUTPUT_DIR, 'jackpot_trend.png'), dpi=300)\n",
    "plt.close()\n",
    "\n",
    "# 4. Phân tích tăng/giảm Jackpot\n",
    "df['Jackpot_Change'] = df['Jackpot'].diff()\n",
    "df['Trend'] = df['Jackpot_Change'].apply(lambda x: 'Tăng' if x > 0 else 'Giảm' if x < 0 else 'Không đổi')\n",
    "trend_counts = df['Trend'].value_counts()\n",
    "print(\"\\nTần suất tăng/giảm Jackpot:\")\n",
    "print(trend_counts)\n",
    "\n",
    "avg_increase = df[df['Jackpot_Change'] > 0]['Jackpot_Change'].mean() / 1e9\n",
    "avg_decrease = df[df['Jackpot_Change'] < 0]['Jackpot_Change'].mean() / 1e9\n",
    "print(f\"\\nGiá trị tăng trung bình: {avg_increase:.2f} tỷ VND\")\n",
    "print(f\"Giá trị giảm trung bình: {avg_decrease:.2f} tỷ VND\")\n",
    "\n",
    "# 5. Phân tích chu kỳ Jackpot\n",
    "df['Jackpot_Reset'] = df['Jackpot_Change'] < -10e9  # Giả định giảm lớn là reset Jackpot\n",
    "cycles = []\n",
    "current_cycle = 0\n",
    "for reset in df['Jackpot_Reset']:\n",
    "    if reset:\n",
    "        cycles.append(current_cycle)\n",
    "        current_cycle = 0\n",
    "    else:\n",
    "        current_cycle += 1\n",
    "if current_cycle > 0:\n",
    "    cycles.append(current_cycle)\n",
    "\n",
    "print(\"\\nPhân tích chu kỳ Jackpot:\")\n",
    "print(f\"- Số chu kỳ: {len(cycles)}\")\n",
    "print(f\"- Độ dài chu kỳ trung bình: {np.mean(cycles):.2f} kỳ\")\n",
    "print(f\"- Độ dài chu kỳ tối đa: {max(cycles)} kỳ\")\n",
    "print(f\"- Độ dài chu kỳ tối thiểu: {min(cycles)} kỳ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b945c77f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cb46a478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tổng số mẫu học: 1306\n",
      "Đã lưu dữ liệu mã hóa: X.npy, y.npy\n",
      "Kích thước tập huấn luyện: (1044, 50, 45)\n",
      "Kích thước tập kiểm tra: (262, 50, 45)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Tận dụng df từ cell trước\n",
    "# Kiểm tra dữ liệu\n",
    "if 'Kết Quả' not in df.columns:\n",
    "    raise ValueError(\"Dữ liệu thiếu cột 'Kết Quả'\")\n",
    "\n",
    "# Chuyển đổi Kết Quả\n",
    "df['Kết Quả'] = df['Kết Quả'].apply(lambda x: json.loads(x) if isinstance(x, str) else x)\n",
    "\n",
    "# Kiểm tra tính hợp lệ\n",
    "df['Valid_Result'] = df['Kết Quả'].apply(validate_result)\n",
    "invalid_results = df[~df['Valid_Result'].apply(lambda x: x[0])]\n",
    "if not invalid_results.empty:\n",
    "    raise ValueError(\"Dữ liệu chứa kết quả không hợp lệ, vui lòng kiểm tra.\")\n",
    "\n",
    "# Mã hóa dữ liệu\n",
    "mlb = MultiLabelBinarizer(classes=range(1, 46))\n",
    "y_encoded = mlb.fit_transform(df['Kết Quả'])\n",
    "\n",
    "# Tạo chuỗi time-series\n",
    "sequence_length = 50\n",
    "X, y = [], []\n",
    "for i in range(len(y_encoded) - sequence_length):\n",
    "    X.append(y_encoded[i:i + sequence_length])\n",
    "    y.append(y_encoded[i + sequence_length])\n",
    "\n",
    "X = np.array(X)  # (samples, sequence_length, 45)\n",
    "y = np.array(y)  # (samples, 45)\n",
    "print(f\"Tổng số mẫu học: {len(X)}\")\n",
    "\n",
    "# Lưu dữ liệu mã hóa\n",
    "np.save(os.path.join(OUTPUT_DIR, 'X.npy'), X)\n",
    "np.save(os.path.join(OUTPUT_DIR, 'y.npy'), y)\n",
    "print(f\"Đã lưu dữ liệu mã hóa: X.npy, y.npy\")\n",
    "\n",
    "# Chia tập huấn luyện và kiểm tra\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "print(f\"Kích thước tập huấn luyện: {X_train.shape}\")\n",
    "print(f\"Kích thước tập kiểm tra: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cff1d466",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Số kỳ quay trong dữ liệu: 1356\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Đọc dữ liệu\n",
    "df = pd.read_csv(r'E:\\vietlot_mega\\data_645/vietlott_645_clean.csv')\n",
    "\n",
    "# Đếm số kỳ quay\n",
    "num_draws = len(df)\n",
    "\n",
    "print(f\"Số kỳ quay trong dữ liệu: {num_draws}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977c4178",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0fff70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-30 16:27:09,543 - INFO - Đang tải dữ liệu từ E:/vietlot_mega\\data_645/vietlott_645_clean.csv...\n",
      "2025-05-30 16:27:09,563 - INFO - Loại bỏ 0 hàng do kết quả không hợp lệ.\n",
      "2025-05-30 16:27:09,569 - INFO - Đã tải 1356 kết quả hợp lệ.\n"
     ]
    }
   ],
   "source": [
    "def load_and_preprocess_data(file_path='E:/vietlot_mega\\data_645/vietlott_645_clean.csv'):\n",
    "    logger.info(f\"Đang tải dữ liệu từ {file_path}...\")\n",
    "    \n",
    "    # Kiểm tra file tồn tại\n",
    "    if not os.path.exists(file_path):\n",
    "        logger.error(f\"File {file_path} không tồn tại.\")\n",
    "        raise FileNotFoundError(f\"File {file_path} không tồn tại.\")\n",
    "    \n",
    "    # Đọc dữ liệu\n",
    "    df = pd.read_csv(file_path, encoding='utf-8')\n",
    "    if not all(col in df.columns for col in ['Ngày', 'Kết Quả']):\n",
    "        logger.error(\"File CSV thiếu cột 'Ngày' hoặc 'Kết Quả'.\")\n",
    "        raise KeyError(\"File CSV thiếu cột cần thiết.\")\n",
    "    \n",
    "    # Chuyển đổi cột Kết Quả\n",
    "    def parse_results(res):\n",
    "        try:\n",
    "            if isinstance(res, str):\n",
    "                numbers = json.loads(res) if '[' in res else [int(x) for x in res.split()]\n",
    "            else:\n",
    "                numbers = res\n",
    "            if len(numbers) == 6 and all(isinstance(x, int) and 1 <= x <= 45 for x in numbers):\n",
    "                return sorted(numbers)\n",
    "            return None\n",
    "        except Exception:\n",
    "            return None\n",
    "    \n",
    "    initial_rows = len(df)\n",
    "    df['Numbers'] = df['Kết Quả'].apply(parse_results)\n",
    "    df = df.dropna(subset=['Numbers'])\n",
    "    logger.info(f\"Loại bỏ {initial_rows - len(df)} hàng do kết quả không hợp lệ.\")\n",
    "    \n",
    "    # Chuyển đổi ngày\n",
    "    df['Date'] = pd.to_datetime(df['Ngày'], format='%Y-%m-%d', errors='coerce')\n",
    "    df = df.dropna(subset=['Date']).sort_values('Date')\n",
    "    \n",
    "    # Thêm đặc trưng\n",
    "    df['Draw'] = range(1, len(df) + 1)\n",
    "    df['DayOfWeek'] = df['Date'].dt.dayofweek\n",
    "    df['Sum'] = df['Numbers'].apply(sum)\n",
    "    df['OddCount'] = df['Numbers'].apply(lambda x: sum(1 for n in x if n % 2 == 1))\n",
    "    df['Range'] = df['Numbers'].apply(lambda x: max(x) - min(x))\n",
    "    \n",
    "    logger.info(f\"Đã tải {len(df)} kết quả hợp lệ.\")\n",
    "    return df\n",
    "\n",
    "# Tải dữ liệu\n",
    "df = load_and_preprocess_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4542cb0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7e9e897a",
   "metadata": {},
   "source": [
    "# LSTM + GRU + Random Fores + Transformer + Tần xuất"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d00500b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-31 15:02:39,091 - INFO - Đang tải và tiền xử lý dữ liệu...\n",
      "2025-05-31 15:02:39,117 - INFO - 5 dòng đầu của dữ liệu:\n",
      "2025-05-31 15:02:39,122 - INFO - \n",
      "            Ngày                   Kết Quả                   Numbers       Date\n",
      "1194  2017-08-01   [5, 10, 14, 23, 24, 38]   [5, 10, 14, 23, 24, 38] 2017-08-01\n",
      "1193  2017-08-03    [4, 9, 24, 25, 27, 45]    [4, 9, 24, 25, 27, 45] 2017-08-03\n",
      "1192  2017-08-05    [1, 5, 11, 32, 40, 45]    [1, 5, 11, 32, 40, 45] 2017-08-05\n",
      "1191  2017-08-08  [19, 36, 39, 41, 46, 51]  [19, 36, 39, 41, 46, 51] 2017-08-08\n",
      "1190  2017-08-10  [10, 11, 19, 41, 50, 54]  [10, 11, 19, 41, 50, 54] 2017-08-10\n",
      "2025-05-31 15:02:39,123 - INFO - 5 dòng cuối của dữ liệu:\n",
      "2025-05-31 15:02:39,128 - INFO - \n",
      "         Ngày                   Kết Quả                   Numbers       Date\n",
      "4  2025-05-17    [2, 7, 26, 29, 41, 50]    [2, 7, 26, 29, 41, 50] 2025-05-17\n",
      "3  2025-05-20  [19, 27, 44, 45, 47, 52]  [19, 27, 44, 45, 47, 52] 2025-05-20\n",
      "2  2025-05-22    [3, 9, 14, 41, 47, 55]    [3, 9, 14, 41, 47, 55] 2025-05-22\n",
      "1  2025-05-24  [19, 20, 27, 30, 45, 55]  [19, 20, 27, 30, 45, 55] 2025-05-24\n",
      "0  2025-05-27   [4, 12, 18, 19, 44, 48]   [4, 12, 18, 19, 44, 48] 2025-05-27\n",
      "2025-05-31 15:02:39,130 - INFO - Tính toán các mẫu thống kê...\n",
      "2025-05-31 15:02:39,270 - INFO - Dữ liệu đã được tải và tiền xử lý thành công. Số kỳ: 1195\n",
      "2025-05-31 15:02:39,271 - INFO - Xác định kỳ quay và ngày quay tiếp theo...\n",
      "2025-05-31 15:02:39,279 - INFO - Ngày cuối trong dữ liệu: 2025-05-27 (Thứ 2)\n",
      "2025-05-31 15:02:39,291 - INFO - Kỳ quay tiếp theo: 1197, Ngày: 2025-05-31\n",
      "2025-05-31 15:02:39,292 - INFO - Chuẩn bị chuỗi dữ liệu...\n",
      "2025-05-31 15:02:39,757 - INFO - Kích thước tập huấn luyện: 990, tập kiểm tra: 175\n",
      "2025-05-31 15:02:39,765 - INFO - Dự đoán 2 bộ số...\n",
      "2025-05-31 15:02:39,768 - INFO - Huấn luyện mô hình LSTM...\n",
      "2025-05-31 15:02:49,658 - INFO - Epoch 1/150 - loss: 0.4778 - val_loss: 0.3499 - precision_at_k: 0.1077 - val_precision_at_k: 0.1105\n",
      "2025-05-31 15:02:50,211 - INFO - Epoch 2/150 - loss: 0.3526 - val_loss: 0.3455 - precision_at_k: 0.1093 - val_precision_at_k: 0.1048\n",
      "2025-05-31 15:02:50,762 - INFO - Epoch 3/150 - loss: 0.3506 - val_loss: 0.3452 - precision_at_k: 0.1000 - val_precision_at_k: 0.1038\n",
      "2025-05-31 15:02:51,307 - INFO - Epoch 4/150 - loss: 0.3494 - val_loss: 0.3451 - precision_at_k: 0.1084 - val_precision_at_k: 0.1048\n",
      "2025-05-31 15:02:51,934 - INFO - Epoch 5/150 - loss: 0.3492 - val_loss: 0.3449 - precision_at_k: 0.1101 - val_precision_at_k: 0.1181\n",
      "2025-05-31 15:02:52,644 - INFO - Epoch 6/150 - loss: 0.3491 - val_loss: 0.3452 - precision_at_k: 0.1040 - val_precision_at_k: 0.1143\n",
      "2025-05-31 15:02:53,207 - INFO - Epoch 7/150 - loss: 0.3486 - val_loss: 0.3450 - precision_at_k: 0.1098 - val_precision_at_k: 0.1038\n",
      "2025-05-31 15:02:53,746 - INFO - Epoch 8/150 - loss: 0.3482 - val_loss: 0.3452 - precision_at_k: 0.1077 - val_precision_at_k: 0.1029\n",
      "2025-05-31 15:02:54,280 - INFO - Epoch 9/150 - loss: 0.3481 - val_loss: 0.3452 - precision_at_k: 0.1145 - val_precision_at_k: 0.0971\n",
      "2025-05-31 15:02:54,836 - INFO - Epoch 10/150 - loss: 0.3476 - val_loss: 0.3450 - precision_at_k: 0.1109 - val_precision_at_k: 0.1152\n",
      "2025-05-31 15:02:55,440 - INFO - Epoch 11/150 - loss: 0.3473 - val_loss: 0.3449 - precision_at_k: 0.1069 - val_precision_at_k: 0.1105\n",
      "2025-05-31 15:02:55,970 - INFO - Epoch 12/150 - loss: 0.3470 - val_loss: 0.3448 - precision_at_k: 0.1168 - val_precision_at_k: 0.1076\n",
      "2025-05-31 15:02:56,544 - INFO - Epoch 13/150 - loss: 0.3469 - val_loss: 0.3447 - precision_at_k: 0.1140 - val_precision_at_k: 0.1114\n",
      "2025-05-31 15:02:57,078 - INFO - Epoch 14/150 - loss: 0.3471 - val_loss: 0.3448 - precision_at_k: 0.1108 - val_precision_at_k: 0.0990\n",
      "2025-05-31 15:02:57,623 - INFO - Epoch 15/150 - loss: 0.3466 - val_loss: 0.3447 - precision_at_k: 0.1158 - val_precision_at_k: 0.0914\n",
      "2025-05-31 15:02:58,161 - INFO - Epoch 16/150 - loss: 0.3468 - val_loss: 0.3447 - precision_at_k: 0.1143 - val_precision_at_k: 0.0990\n",
      "2025-05-31 15:02:58,699 - INFO - Epoch 17/150 - loss: 0.3467 - val_loss: 0.3448 - precision_at_k: 0.1236 - val_precision_at_k: 0.1105\n",
      "2025-05-31 15:02:59,248 - INFO - Epoch 18/150 - loss: 0.3471 - val_loss: 0.3448 - precision_at_k: 0.1027 - val_precision_at_k: 0.1048\n",
      "2025-05-31 15:02:59,803 - INFO - Epoch 19/150 - loss: 0.3471 - val_loss: 0.3447 - precision_at_k: 0.1052 - val_precision_at_k: 0.0962\n",
      "2025-05-31 15:03:00,352 - INFO - Epoch 20/150 - loss: 0.3468 - val_loss: 0.3448 - precision_at_k: 0.1173 - val_precision_at_k: 0.1019\n",
      "2025-05-31 15:03:00,908 - INFO - Epoch 21/150 - loss: 0.3470 - val_loss: 0.3448 - precision_at_k: 0.1082 - val_precision_at_k: 0.0990\n",
      "2025-05-31 15:03:01,453 - INFO - Epoch 22/150 - loss: 0.3466 - val_loss: 0.3447 - precision_at_k: 0.1160 - val_precision_at_k: 0.1029\n",
      "2025-05-31 15:03:02,007 - INFO - Epoch 23/150 - loss: 0.3471 - val_loss: 0.3447 - precision_at_k: 0.1088 - val_precision_at_k: 0.1038\n",
      "2025-05-31 15:03:02,009 - INFO - Huấn luyện mô hình GRU...\n",
      "2025-05-31 15:03:06,437 - INFO - Epoch 1/150 - loss: 0.4871 - val_loss: 0.3526 - precision_at_k: 0.1054 - val_precision_at_k: 0.1162\n",
      "2025-05-31 15:03:07,006 - INFO - Epoch 2/150 - loss: 0.3546 - val_loss: 0.3461 - precision_at_k: 0.1088 - val_precision_at_k: 0.1114\n",
      "2025-05-31 15:03:07,532 - INFO - Epoch 3/150 - loss: 0.3513 - val_loss: 0.3453 - precision_at_k: 0.1093 - val_precision_at_k: 0.1152\n",
      "2025-05-31 15:03:08,060 - INFO - Epoch 4/150 - loss: 0.3506 - val_loss: 0.3448 - precision_at_k: 0.1136 - val_precision_at_k: 0.1133\n",
      "2025-05-31 15:03:08,599 - INFO - Epoch 5/150 - loss: 0.3507 - val_loss: 0.3449 - precision_at_k: 0.1104 - val_precision_at_k: 0.1152\n",
      "2025-05-31 15:03:09,126 - INFO - Epoch 6/150 - loss: 0.3496 - val_loss: 0.3450 - precision_at_k: 0.1045 - val_precision_at_k: 0.1067\n",
      "2025-05-31 15:03:09,702 - INFO - Epoch 7/150 - loss: 0.3496 - val_loss: 0.3451 - precision_at_k: 0.1064 - val_precision_at_k: 0.1067\n",
      "2025-05-31 15:03:10,268 - INFO - Epoch 8/150 - loss: 0.3484 - val_loss: 0.3447 - precision_at_k: 0.1121 - val_precision_at_k: 0.1029\n",
      "2025-05-31 15:03:10,806 - INFO - Epoch 9/150 - loss: 0.3488 - val_loss: 0.3450 - precision_at_k: 0.1051 - val_precision_at_k: 0.1057\n",
      "2025-05-31 15:03:11,352 - INFO - Epoch 10/150 - loss: 0.3480 - val_loss: 0.3449 - precision_at_k: 0.1138 - val_precision_at_k: 0.1124\n",
      "2025-05-31 15:03:11,918 - INFO - Epoch 11/150 - loss: 0.3481 - val_loss: 0.3448 - precision_at_k: 0.1109 - val_precision_at_k: 0.1114\n",
      "2025-05-31 15:03:12,441 - INFO - Epoch 12/150 - loss: 0.3478 - val_loss: 0.3449 - precision_at_k: 0.1098 - val_precision_at_k: 0.1067\n",
      "2025-05-31 15:03:12,971 - INFO - Epoch 13/150 - loss: 0.3483 - val_loss: 0.3450 - precision_at_k: 0.1098 - val_precision_at_k: 0.1086\n",
      "2025-05-31 15:03:13,498 - INFO - Epoch 14/150 - loss: 0.3472 - val_loss: 0.3449 - precision_at_k: 0.1135 - val_precision_at_k: 0.1038\n",
      "2025-05-31 15:03:14,023 - INFO - Epoch 15/150 - loss: 0.3476 - val_loss: 0.3449 - precision_at_k: 0.1157 - val_precision_at_k: 0.1057\n",
      "2025-05-31 15:03:14,558 - INFO - Epoch 16/150 - loss: 0.3477 - val_loss: 0.3449 - precision_at_k: 0.1059 - val_precision_at_k: 0.1057\n",
      "2025-05-31 15:03:14,560 - INFO - Huấn luyện mô hình Transformer...\n",
      "2025-05-31 15:03:18,006 - INFO - Epoch 1/150 - loss: 1.9970 - val_loss: 1.3063 - precision_at_k: 0.1106 - val_precision_at_k: 0.1019\n",
      "2025-05-31 15:03:18,443 - INFO - Epoch 2/150 - loss: 1.0075 - val_loss: 0.7171 - precision_at_k: 0.1047 - val_precision_at_k: 0.1095\n",
      "2025-05-31 15:03:18,833 - INFO - Epoch 3/150 - loss: 0.6058 - val_loss: 0.4857 - precision_at_k: 0.1094 - val_precision_at_k: 0.1086\n",
      "2025-05-31 15:03:19,205 - INFO - Epoch 4/150 - loss: 0.4502 - val_loss: 0.3996 - precision_at_k: 0.1135 - val_precision_at_k: 0.1114\n",
      "2025-05-31 15:03:19,707 - INFO - Epoch 5/150 - loss: 0.3937 - val_loss: 0.3707 - precision_at_k: 0.1128 - val_precision_at_k: 0.1238\n",
      "2025-05-31 15:03:20,069 - INFO - Epoch 6/150 - loss: 0.3730 - val_loss: 0.3574 - precision_at_k: 0.1094 - val_precision_at_k: 0.1190\n",
      "2025-05-31 15:03:20,458 - INFO - Epoch 7/150 - loss: 0.3632 - val_loss: 0.3511 - precision_at_k: 0.1111 - val_precision_at_k: 0.1057\n",
      "2025-05-31 15:03:20,823 - INFO - Epoch 8/150 - loss: 0.3583 - val_loss: 0.3526 - precision_at_k: 0.1187 - val_precision_at_k: 0.1000\n",
      "2025-05-31 15:03:21,203 - INFO - Epoch 9/150 - loss: 0.3574 - val_loss: 0.3478 - precision_at_k: 0.1153 - val_precision_at_k: 0.1095\n",
      "2025-05-31 15:03:21,568 - INFO - Epoch 10/150 - loss: 0.3562 - val_loss: 0.3469 - precision_at_k: 0.1094 - val_precision_at_k: 0.1000\n",
      "2025-05-31 15:03:21,926 - INFO - Epoch 11/150 - loss: 0.3548 - val_loss: 0.3477 - precision_at_k: 0.1076 - val_precision_at_k: 0.1105\n",
      "2025-05-31 15:03:22,287 - INFO - Epoch 12/150 - loss: 0.3544 - val_loss: 0.3486 - precision_at_k: 0.1088 - val_precision_at_k: 0.1105\n",
      "2025-05-31 15:03:22,671 - INFO - Epoch 13/150 - loss: 0.3544 - val_loss: 0.3473 - precision_at_k: 0.1024 - val_precision_at_k: 0.1029\n",
      "2025-05-31 15:03:23,057 - INFO - Epoch 14/150 - loss: 0.3537 - val_loss: 0.3478 - precision_at_k: 0.1082 - val_precision_at_k: 0.1229\n",
      "2025-05-31 15:03:23,406 - INFO - Epoch 15/150 - loss: 0.3525 - val_loss: 0.3467 - precision_at_k: 0.1111 - val_precision_at_k: 0.1067\n",
      "2025-05-31 15:03:23,765 - INFO - Epoch 16/150 - loss: 0.3522 - val_loss: 0.3473 - precision_at_k: 0.1061 - val_precision_at_k: 0.1095\n",
      "2025-05-31 15:03:24,126 - INFO - Epoch 17/150 - loss: 0.3516 - val_loss: 0.3465 - precision_at_k: 0.1153 - val_precision_at_k: 0.1086\n",
      "2025-05-31 15:03:24,671 - INFO - Epoch 18/150 - loss: 0.3516 - val_loss: 0.3460 - precision_at_k: 0.1148 - val_precision_at_k: 0.1257\n",
      "2025-05-31 15:03:25,031 - INFO - Epoch 19/150 - loss: 0.3518 - val_loss: 0.3465 - precision_at_k: 0.1123 - val_precision_at_k: 0.1190\n",
      "2025-05-31 15:03:25,399 - INFO - Epoch 20/150 - loss: 0.3519 - val_loss: 0.3466 - precision_at_k: 0.1098 - val_precision_at_k: 0.1067\n",
      "2025-05-31 15:03:25,755 - INFO - Epoch 21/150 - loss: 0.3522 - val_loss: 0.3467 - precision_at_k: 0.1096 - val_precision_at_k: 0.1057\n",
      "2025-05-31 15:03:26,156 - INFO - Epoch 22/150 - loss: 0.3510 - val_loss: 0.3467 - precision_at_k: 0.1148 - val_precision_at_k: 0.1105\n",
      "2025-05-31 15:03:26,526 - INFO - Epoch 23/150 - loss: 0.3512 - val_loss: 0.3463 - precision_at_k: 0.1118 - val_precision_at_k: 0.1152\n",
      "2025-05-31 15:03:26,897 - INFO - Epoch 24/150 - loss: 0.3508 - val_loss: 0.3460 - precision_at_k: 0.1088 - val_precision_at_k: 0.1057\n",
      "2025-05-31 15:03:27,307 - INFO - Epoch 25/150 - loss: 0.3499 - val_loss: 0.3459 - precision_at_k: 0.1162 - val_precision_at_k: 0.1048\n",
      "2025-05-31 15:03:27,669 - INFO - Epoch 26/150 - loss: 0.3506 - val_loss: 0.3458 - precision_at_k: 0.1126 - val_precision_at_k: 0.1124\n",
      "2025-05-31 15:03:28,033 - INFO - Epoch 27/150 - loss: 0.3507 - val_loss: 0.3458 - precision_at_k: 0.1101 - val_precision_at_k: 0.1162\n",
      "2025-05-31 15:03:28,444 - INFO - Epoch 28/150 - loss: 0.3506 - val_loss: 0.3455 - precision_at_k: 0.1141 - val_precision_at_k: 0.1038\n",
      "2025-05-31 15:03:28,812 - INFO - Epoch 29/150 - loss: 0.3500 - val_loss: 0.3460 - precision_at_k: 0.1146 - val_precision_at_k: 0.1105\n",
      "2025-05-31 15:03:29,162 - INFO - Epoch 30/150 - loss: 0.3508 - val_loss: 0.3463 - precision_at_k: 0.1066 - val_precision_at_k: 0.0990\n",
      "2025-05-31 15:03:29,517 - INFO - Epoch 31/150 - loss: 0.3503 - val_loss: 0.3458 - precision_at_k: 0.1141 - val_precision_at_k: 0.1010\n",
      "2025-05-31 15:03:29,867 - INFO - Epoch 32/150 - loss: 0.3496 - val_loss: 0.3459 - precision_at_k: 0.1133 - val_precision_at_k: 0.1010\n",
      "2025-05-31 15:03:30,221 - INFO - Epoch 33/150 - loss: 0.3502 - val_loss: 0.3459 - precision_at_k: 0.1148 - val_precision_at_k: 0.0952\n",
      "2025-05-31 15:03:30,582 - INFO - Epoch 34/150 - loss: 0.3501 - val_loss: 0.3460 - precision_at_k: 0.1116 - val_precision_at_k: 0.1048\n",
      "2025-05-31 15:03:30,936 - INFO - Epoch 35/150 - loss: 0.3500 - val_loss: 0.3459 - precision_at_k: 0.1192 - val_precision_at_k: 0.0971\n",
      "2025-05-31 15:03:31,309 - INFO - Epoch 36/150 - loss: 0.3498 - val_loss: 0.3459 - precision_at_k: 0.1098 - val_precision_at_k: 0.0952\n",
      "2025-05-31 15:03:31,311 - INFO - Huấn luyện Random Forest...\n",
      "2025-05-31 15:03:41,010 - INFO - Đã lưu dự đoán vào predictions.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dự đoán cho kỳ quay 1197 (ngày 2025-05-31 - Hôm nay, 31/05/2025):\n",
      "Bộ 1: [3, 15, 19, 39, 41, 44]\n",
      "Bộ 2: [3, 15, 19, 39, 41, 44]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ast import literal_eval\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, LayerNormalization, MultiHeadAttention, Input, Flatten, LSTM, GRU, Add\n",
    "from tensorflow.keras.callbacks import EarlyStopping, Callback, ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.metrics import Precision\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import tensorflow as tf\n",
    "import random\n",
    "from collections import Counter\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "import logging\n",
    "import warnings\n",
    "import itertools\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Thiết lập logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Thiết lập seed\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "tf.random.set_seed(RANDOM_SEED)\n",
    "random.seed(RANDOM_SEED)\n",
    "\n",
    "# Hằng số cấu hình\n",
    "FILE_PATH = 'E:\\\\vietlot_mega\\\\data_655\\\\vietlott_655_clean.csv'\n",
    "SEQUENCE_LENGTH = 30\n",
    "CONFIG = {\n",
    "    'num_heads': 4,\n",
    "    'ff_dim': 128,\n",
    "    'learning_rate': 0.001,\n",
    "    'batch_size': 32,\n",
    "    'epochs': 150,\n",
    "    'dropout_rate': 0.3,\n",
    "    'hist_ratio': 0.3,\n",
    "    'lstm_units': 64,\n",
    "    'gru_units': 64,\n",
    "    'rf_n_estimators': 100\n",
    "}\n",
    "\n",
    "# Callback\n",
    "class PrintTrainingMetrics(Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logging.info(f\"Epoch {epoch+1}/{self.params['epochs']} - \"\n",
    "                     f\"loss: {logs['loss']:.4f} - val_loss: {logs['val_loss']:.4f} - \"\n",
    "                     f\"precision_at_k: {logs.get('precision_at_k', 0):.4f} - \"\n",
    "                     f\"val_precision_at_k: {logs.get('val_precision_at_k', 0):.4f}\")\n",
    "\n",
    "class VietlottPredictor:\n",
    "    def __init__(self, sequence_length=SEQUENCE_LENGTH, file_path=FILE_PATH, config=CONFIG):\n",
    "        self.sequence_length = sequence_length\n",
    "        self.file_path = file_path\n",
    "        self.config = config\n",
    "        self.results = None\n",
    "        self.df = None\n",
    "        self.scaler = None\n",
    "        self.feature_scaler = None\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = None, None, None, None\n",
    "        self.last_sequence = None\n",
    "        self.statistical_patterns = {}\n",
    "        self.next_draw = None\n",
    "        self.next_date = None\n",
    "        self.rf_model = None\n",
    "\n",
    "    def get_next_draw(self, steps_ahead=1):\n",
    "        if self.df is None or self.df.empty:\n",
    "            raise ValueError(\"Dữ liệu chưa được tải.\")\n",
    "        logging.info(\"Xác định kỳ quay và ngày quay tiếp theo...\")\n",
    "        self.df['Draw'] = range(1, len(self.df) + 1)\n",
    "        last_draw = self.df['Draw'].iloc[-1]\n",
    "        last_date = self.df['Date'].iloc[-1]\n",
    "        logging.info(f\"Ngày cuối trong dữ liệu: {last_date.strftime('%Y-%m-%d')} (Thứ {last_date.weekday()+1})\")\n",
    "        target_days = [1, 3, 5]  # Thứ Ba, thứ Năm, thứ Bảy\n",
    "        current_date = last_date\n",
    "        for _ in range(steps_ahead):\n",
    "            current_day = current_date.weekday()\n",
    "            days_ahead = min((target - current_day) % 7 or 7 for target in target_days)\n",
    "            current_date += timedelta(days=days_ahead)\n",
    "        self.next_date = current_date\n",
    "        self.next_draw = last_draw + steps_ahead\n",
    "        logging.info(f\"Kỳ quay tiếp theo: {self.next_draw}, Ngày: {self.next_date.strftime('%Y-%m-%d')}\")\n",
    "        return self.next_draw, self.next_date\n",
    "\n",
    "    def compute_statistical_patterns(self):\n",
    "        logging.info(\"Tính toán các mẫu thống kê...\")\n",
    "        all_numbers = np.array([num for draw in self.results for num in draw])\n",
    "        total_draws = len(self.results)\n",
    "\n",
    "        freq = np.bincount(all_numbers, minlength=56)[1:]\n",
    "        self.statistical_patterns['frequencies'] = {i: int(f) for i, f in enumerate(freq, 1)}\n",
    "        self.statistical_patterns['number_probabilities'] = {i: f / (total_draws * 6) for i, f in enumerate(freq, 1)}\n",
    "        candidate_numbers = (np.argsort(freq)[::-1][:20] + 1).tolist()\n",
    "        self.statistical_patterns['candidate_numbers'] = candidate_numbers if candidate_numbers else list(range(1, 56))\n",
    "\n",
    "        recent_numbers = np.array([num for draw in self.results[-15:] for num in draw])\n",
    "        recent_freq = np.bincount(recent_numbers, minlength=56)[1:]\n",
    "        self.statistical_patterns['recent_frequencies'] = {i: f / 90 for i, f in enumerate(recent_freq, 1)}\n",
    "        recent_top_10 = (np.argsort(recent_freq)[::-1][:10] + 1).tolist()\n",
    "        self.statistical_patterns['recent_top_10'] = recent_top_10\n",
    "\n",
    "        pair_counts = Counter()\n",
    "        for draw in self.results:\n",
    "            for pair in itertools.combinations(sorted(draw), 2):\n",
    "                pair_counts[pair] += 1\n",
    "        self.statistical_patterns['pair_probabilities'] = {k: v / total_draws for k, v in pair_counts.items()}\n",
    "\n",
    "        last_appearance = {}\n",
    "        for i, draw in enumerate(reversed(self.results)):\n",
    "            for num in draw:\n",
    "                if num not in last_appearance:\n",
    "                    last_appearance[num] = i\n",
    "        self.statistical_patterns['last_appearance'] = last_appearance\n",
    "\n",
    "        recent_momentum = {}\n",
    "        recent_draws = self.results[-5:]\n",
    "        for num in range(1, 56):\n",
    "            momentum = sum(1 for draw in recent_draws if num in draw) / 5\n",
    "            recent_momentum[num] = momentum\n",
    "        self.statistical_patterns['recent_momentum'] = recent_momentum\n",
    "\n",
    "        logging.debug(f\"Candidate numbers: {self.statistical_patterns['candidate_numbers']}\")\n",
    "        logging.debug(f\"Recent top 10: {self.statistical_patterns['recent_top_10']}\")\n",
    "\n",
    "    def load_and_preprocess_data(self):\n",
    "        logging.info(\"Đang tải và tiền xử lý dữ liệu...\")\n",
    "        try:\n",
    "            if not os.path.exists(self.file_path):\n",
    "                logging.error(f\"File không tồn tại: {self.file_path}\")\n",
    "                raise FileNotFoundError(f\"File không tồn tại: {self.file_path}\")\n",
    "            try:\n",
    "                self.df = pd.read_csv(self.file_path, encoding='utf-8')\n",
    "            except UnicodeDecodeError:\n",
    "                logging.warning(\"Không thể đọc file với UTF-8, thử encoding latin1...\")\n",
    "                self.df = pd.read_csv(self.file_path, encoding='latin1')\n",
    "            expected_columns = ['Ngày', 'Kết Quả']\n",
    "            if not all(col in self.df.columns for col in expected_columns):\n",
    "                logging.error(f\"Thiếu cột cần thiết. Cột có sẵn: {self.df.columns.tolist()}\")\n",
    "                raise ValueError(f\"CSV phải chứa các cột: {expected_columns}\")\n",
    "            self.df['Numbers'] = self.df['Kết Quả'].apply(literal_eval)\n",
    "            self.df = self.df.dropna(subset=['Numbers'])\n",
    "            self.df['Date'] = pd.to_datetime(self.df['Ngày'], format='%Y-%m-%d', errors='coerce')\n",
    "            self.df = self.df.dropna(subset=['Date']).sort_values('Date')\n",
    "            logging.info(\"5 dòng đầu của dữ liệu:\")\n",
    "            logging.info(f\"\\n{self.df.head().to_string()}\")\n",
    "            logging.info(\"5 dòng cuối của dữ liệu:\")\n",
    "            logging.info(f\"\\n{self.df.tail().to_string()}\")\n",
    "            if len(self.df) < 600:\n",
    "                logging.error(f\"Dữ liệu chỉ có {len(self.df)} kỳ, cần ít nhất 600 kỳ.\")\n",
    "                raise ValueError(f\"Dữ liệu chỉ có {len(self.df)} kỳ, cần ít nhất 600 kỳ.\")\n",
    "            if len(set([n for draw in self.df['Numbers'] for n in draw])) < 55:\n",
    "                logging.error(\"Dữ liệu không chứa đủ 55 số khác nhau.\")\n",
    "                raise ValueError(\"Dữ liệu không chứa đủ 55 số khác nhau.\")\n",
    "            if (self.df['Date'].max() - self.df['Date'].min()).days < 1095:\n",
    "                logging.error(\"Dữ liệu cần trải dài ít nhất 3 năm.\")\n",
    "                raise ValueError(\"Dữ liệu cần trải dài ít nhất 3 năm.\")\n",
    "            self.results = self.df['Numbers'].tolist()\n",
    "            self.compute_statistical_patterns()\n",
    "            self.df['OddCount'] = self.df['Numbers'].apply(lambda x: sum(1 for n in x if n % 2 == 1))\n",
    "            self.df['Sum'] = self.df['Numbers'].apply(lambda x: np.log1p(sum(x)))\n",
    "            self.df['Range'] = self.df['Numbers'].apply(lambda x: np.log1p(max(x) - min(x)))\n",
    "            self.df['ClusterCount'] = self.df['Numbers'].apply(lambda x: sum(1 for n in x if 1 <= n <= 18) / 6 + sum(1 for n in x if 19 <= n <= 36) / 6 + sum(1 for n in x if 37 <= n <= 55) / 6)\n",
    "            self.df['RecentFreq'] = self.df['Numbers'].apply(lambda x: sum(self.statistical_patterns['recent_frequencies'].get(n, 0) for n in x))\n",
    "            self.df['ConsecutiveCount'] = self.df['Numbers'].apply(lambda x: sum(1 for i in range(len(x)-1) if sorted(x)[i+1] == sorted(x)[i] + 1))\n",
    "            self.df['DeltaSum'] = self.df['Sum'].diff().fillna(0)\n",
    "            self.df['NumberGaps'] = self.df['Numbers'].apply(lambda x: np.mean([sorted(x)[i+1] - sorted(x)[i] for i in range(len(x)-1)]))\n",
    "            self.df['RecentHotSpot'] = self.df['Numbers'].apply(lambda x: sum(1 for n in x if n in [num for draw in self.results[-5:] for num in draw]) / 6)\n",
    "            self.df['PatternScore'] = self.df['Numbers'].apply(lambda x: sum(self.statistical_patterns['pair_probabilities'].get(tuple(sorted([a, b])), 0) for a, b in itertools.combinations(x, 2)))\n",
    "            self.df['LastAppearance'] = self.df['Numbers'].apply(lambda x: np.mean([self.statistical_patterns['last_appearance'].get(n, len(self.results)) for n in x]))\n",
    "            self.df['RecentMomentum'] = self.df['Numbers'].apply(lambda x: np.mean([self.statistical_patterns['recent_momentum'].get(n, 0) for n in x]))\n",
    "            logging.info(f\"Dữ liệu đã được tải và tiền xử lý thành công. Số kỳ: {len(self.df)}\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Lỗi khi tải dữ liệu: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def prepare_sequences(self):\n",
    "        logging.info(\"Chuẩn bị chuỗi dữ liệu...\")\n",
    "        try:\n",
    "            sequences = []\n",
    "            targets = []\n",
    "            features = []\n",
    "            for i in range(len(self.results) - self.sequence_length):\n",
    "                seq = self.results[i:i + self.sequence_length]\n",
    "                target = self.results[i + self.sequence_length]\n",
    "                seq_features = [\n",
    "                    self.df['OddCount'].iloc[i:i + self.sequence_length].values,\n",
    "                    self.df['Sum'].iloc[i:i + self.sequence_length].values,\n",
    "                    self.df['Range'].iloc[i:i + self.sequence_length].values,\n",
    "                    self.df['ClusterCount'].iloc[i:i + self.sequence_length].values,\n",
    "                    self.df['RecentFreq'].iloc[i:i + self.sequence_length].values,\n",
    "                    self.df['ConsecutiveCount'].iloc[i:i + self.sequence_length].values,\n",
    "                    self.df['DeltaSum'].iloc[i:i + self.sequence_length].values,\n",
    "                    self.df['NumberGaps'].iloc[i:i + self.sequence_length].values,\n",
    "                    self.df['RecentHotSpot'].iloc[i:i + self.sequence_length].values,\n",
    "                    self.df['PatternScore'].iloc[i:i + self.sequence_length].values,\n",
    "                    self.df['LastAppearance'].iloc[i:i + self.sequence_length].values,\n",
    "                    self.df['RecentMomentum'].iloc[i:i + self.sequence_length].values\n",
    "                ]\n",
    "                sequences.append(seq)\n",
    "                targets.append(target)\n",
    "                features.append(np.stack(seq_features, axis=-1))\n",
    "            X = np.array(sequences)\n",
    "            X_features = np.array(features)\n",
    "            y = np.array(targets)\n",
    "            self.scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "            X_reshaped = X.reshape(-1, X.shape[-1])\n",
    "            X_scaled = self.scaler.fit_transform(X_reshaped)\n",
    "            X = X_scaled.reshape(X.shape)\n",
    "            self.feature_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "            X_features_reshaped = X_features.reshape(-1, X_features.shape[-1])\n",
    "            X_features_scaled = self.feature_scaler.fit_transform(X_features_reshaped)\n",
    "            X_features = X_features_scaled.reshape(X_features.shape)\n",
    "            X = np.concatenate([X, X_features], axis=-1)\n",
    "            from sklearn.model_selection import train_test_split\n",
    "            self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(\n",
    "                X, y, test_size=0.15, random_state=RANDOM_SEED, shuffle=False\n",
    "            )\n",
    "            logging.info(f\"Kích thước tập huấn luyện: {len(self.X_train)}, tập kiểm tra: {len(self.X_test)}\")\n",
    "            last_sequence = np.array(self.results[-self.sequence_length:])\n",
    "            last_features = np.stack([\n",
    "                self.df['OddCount'].iloc[-self.sequence_length:].values,\n",
    "                self.df['Sum'].iloc[-self.sequence_length:].values,\n",
    "                self.df['Range'].iloc[-self.sequence_length:].values,\n",
    "                self.df['ClusterCount'].iloc[-self.sequence_length:].values,\n",
    "                self.df['RecentFreq'].iloc[-self.sequence_length:].values,\n",
    "                self.df['ConsecutiveCount'].iloc[-self.sequence_length:].values,\n",
    "                self.df['DeltaSum'].iloc[-self.sequence_length:].values,\n",
    "                self.df['NumberGaps'].iloc[-self.sequence_length:].values,\n",
    "                self.df['RecentHotSpot'].iloc[-self.sequence_length:].values,\n",
    "                self.df['PatternScore'].iloc[-self.sequence_length:].values,\n",
    "                self.df['LastAppearance'].iloc[-self.sequence_length:].values,\n",
    "                self.df['RecentMomentum'].iloc[-self.sequence_length:].values\n",
    "            ], axis=-1)\n",
    "            last_sequence_reshaped = last_sequence.reshape(-1, last_sequence.shape[-1])\n",
    "            last_sequence_scaled = self.scaler.transform(last_sequence_reshaped).reshape(1, self.sequence_length, 6)\n",
    "            last_features_reshaped = last_features.reshape(-1, last_features.shape[-1])\n",
    "            last_features_scaled = self.feature_scaler.transform(last_features_reshaped).reshape(1, self.sequence_length, 12)\n",
    "            self.last_sequence = np.concatenate([last_sequence_scaled, last_features_scaled], axis=-1)\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Lỗi khi chuẩn bị chuỗi: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def positional_encoding(self, seq_len, d_model):\n",
    "        position = np.arange(seq_len)[:, np.newaxis]\n",
    "        div_term = np.exp(np.arange(0, d_model, 2) * (-np.log(10000.0) / d_model))\n",
    "        pos_encoding = np.zeros((seq_len, d_model))\n",
    "        pos_encoding[:, 0::2] = np.sin(position * div_term)\n",
    "        pos_encoding[:, 1::2] = np.cos(position * div_term)\n",
    "        return tf.cast(pos_encoding[np.newaxis, ...], dtype=tf.float32)\n",
    "\n",
    "    def build_lstm_model(self):\n",
    "        inputs = Input(shape=(self.sequence_length, 18))\n",
    "        x = LSTM(self.config['lstm_units'], return_sequences=True)(inputs)\n",
    "        x = Dropout(self.config['dropout_rate'])(x)\n",
    "        x = LSTM(self.config['lstm_units'])(x)\n",
    "        x = Dropout(self.config['dropout_rate'])(x)\n",
    "        x = Dense(128, activation='relu')(x)\n",
    "        outputs = Dense(55, activation='sigmoid')(x)\n",
    "        model = Model(inputs, outputs)\n",
    "        model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=self.config['learning_rate']),\n",
    "                      loss='binary_crossentropy', metrics=[Precision(top_k=6, name='precision_at_k')])\n",
    "        return model\n",
    "\n",
    "    def build_gru_model(self):\n",
    "        inputs = Input(shape=(self.sequence_length, 18))\n",
    "        x = GRU(self.config['gru_units'], return_sequences=True)(inputs)\n",
    "        x = Dropout(self.config['dropout_rate'])(x)\n",
    "        x = GRU(self.config['gru_units'])(x)\n",
    "        x = Dropout(self.config['dropout_rate'])(x)\n",
    "        x = Dense(128, activation='relu')(x)\n",
    "        outputs = Dense(55, activation='sigmoid')(x)\n",
    "        model = Model(inputs, outputs)\n",
    "        model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=self.config['learning_rate']),\n",
    "                      loss='binary_crossentropy', metrics=[Precision(top_k=6, name='precision_at_k')])\n",
    "        return model\n",
    "\n",
    "    def build_transformer_model(self):\n",
    "        inputs = Input(shape=(self.sequence_length, 18))\n",
    "        pos_encoding = self.positional_encoding(self.sequence_length, 18)\n",
    "        x = Add()([inputs, pos_encoding])\n",
    "        x = MultiHeadAttention(num_heads=self.config['num_heads'], key_dim=64)(x, x)\n",
    "        x = Dropout(self.config['dropout_rate'])(x)\n",
    "        x = LayerNormalization(epsilon=1e-6)(x + inputs)\n",
    "        ff = Dense(self.config['ff_dim'], activation='relu')(x)\n",
    "        ff = Dense(inputs.shape[-1])(ff)\n",
    "        x = Dropout(self.config['dropout_rate'])(ff)\n",
    "        x = LayerNormalization(epsilon=1e-6)(x + ff)\n",
    "        x = Flatten()(x)\n",
    "        x = Dense(128, activation='relu', kernel_regularizer=l2(0.01))(x)\n",
    "        x = Dropout(self.config['dropout_rate'])(x)\n",
    "        outputs = Dense(55, activation='sigmoid')(x)\n",
    "        model = Model(inputs, outputs)\n",
    "        model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=self.config['learning_rate']),\n",
    "                      loss='binary_crossentropy', metrics=[Precision(top_k=6, name='precision_at_k')])\n",
    "        return model\n",
    "\n",
    "    def train_rf_model(self):\n",
    "        logging.info(\"Huấn luyện Random Forest...\")\n",
    "        y_train_rf = np.zeros((len(self.y_train), 55))\n",
    "        for i, draw in enumerate(self.y_train):\n",
    "            for num in draw:\n",
    "                y_train_rf[i, num-1] = 1\n",
    "\n",
    "        X_train_features = self.X_train[:, :, 6:]\n",
    "        X_train_rf = X_train_features.reshape(X_train_features.shape[0], -1)\n",
    "\n",
    "        self.rf_model = RandomForestClassifier(n_estimators=self.config['rf_n_estimators'], random_state=RANDOM_SEED)\n",
    "        self.rf_model.fit(X_train_rf, y_train_rf)\n",
    "\n",
    "    def optimize_numbers(self, nums, probs, iteration=0):\n",
    "        \"\"\"Tối ưu hóa bộ số với sự đa dạng hơn.\"\"\"\n",
    "        logging.debug(f\"Optimizing input (iteration {iteration}): {nums}\")\n",
    "        nums = sorted(list(set(nums)))\n",
    "        target_len = 6\n",
    "\n",
    "        # Bổ sung số ngẫu nhiên để tạo sự đa dạng\n",
    "        available = [n for n in self.statistical_patterns.get('recent_top_10', []) if n not in nums]\n",
    "        if len(available) < target_len - len(nums):\n",
    "            available.extend([n for n in self.statistical_patterns.get('candidate_numbers', []) if n not in nums and n not in available])\n",
    "        while len(nums) < target_len:\n",
    "            if not available:\n",
    "                available = [n for n in range(1, 56) if n not in nums]\n",
    "            # Chọn ngẫu nhiên với xác suất dựa trên tần suất\n",
    "            probs_available = [self.statistical_patterns.get('recent_frequencies', {}).get(n, 0) for n in available]\n",
    "            probs_available = [p if p > 0 else 0.01 for p in probs_available]  # Đảm bảo không có xác suất 0\n",
    "            probs_available = np.array(probs_available) / sum(probs_available)\n",
    "            chosen = np.random.choice(available, p=probs_available)\n",
    "            nums.append(chosen)\n",
    "            nums = sorted(list(set(nums)))\n",
    "            available = [n for n in available if n != chosen]\n",
    "\n",
    "        # Tối ưu hóa với nhiều lần lặp\n",
    "        best_nums = nums.copy()\n",
    "        best_score = sum(probs[n-1] + self.statistical_patterns.get('recent_frequencies', {}).get(n, 0) +\n",
    "                         3.0 * self.statistical_patterns.get('recent_momentum', {}).get(n, 0) -\n",
    "                         0.1 * self.statistical_patterns.get('last_appearance', {}).get(n, len(self.results))\n",
    "                         for n in nums)\n",
    "\n",
    "        for _ in range(30):  # Tăng số lần lặp để thử nhiều tổ hợp hơn\n",
    "            temp_nums = nums.copy()\n",
    "            idx = random.randint(0, len(temp_nums) - 1)\n",
    "            available = [n for n in self.statistical_patterns.get('recent_top_10', []) if n not in temp_nums] or \\\n",
    "                        [n for n in range(1, 56) if n not in temp_nums]\n",
    "            if available:\n",
    "                # Chọn số mới với xác suất dựa trên tần suất\n",
    "                probs_available = [self.statistical_patterns.get('recent_frequencies', {}).get(n, 0) for n in available]\n",
    "                probs_available = [p if p > 0 else 0.01 for p in probs_available]\n",
    "                probs_available = np.array(probs_available) / sum(probs_available)\n",
    "                new_num = np.random.choice(available, p=probs_available)\n",
    "                temp_nums[idx] = new_num\n",
    "                temp_nums = sorted(list(set(temp_nums)))\n",
    "\n",
    "            total = sum(temp_nums)\n",
    "            odd_count = sum(1 for n in temp_nums if n % 2 == 1)\n",
    "            range_dist = (any(1 <= n <= 18 for n in temp_nums) and\n",
    "                          any(19 <= n <= 36 for n in temp_nums) and\n",
    "                          any(37 <= n <= 55 for n in temp_nums))\n",
    "            consecutive_count = sum(1 for i in range(len(temp_nums)-1) if temp_nums[i+1] == temp_nums[i] + 1)\n",
    "            recent_top_count = sum(1 for n in temp_nums if n in self.statistical_patterns.get('recent_top_10', []))\n",
    "            last_appearance_count = sum(1 for n in temp_nums if self.statistical_patterns.get('last_appearance', {}).get(n, len(self.results)) <= 5)\n",
    "\n",
    "            if (150 <= total <= 190 and odd_count in [3, 4] and range_dist and\n",
    "                consecutive_count <= 2 and recent_top_count >= 4 and last_appearance_count >= 3):\n",
    "                score = sum(probs[n-1] + self.statistical_patterns.get('recent_frequencies', {}).get(n, 0) +\n",
    "                            3.0 * self.statistical_patterns.get('recent_momentum', {}).get(n, 0) -\n",
    "                            0.1 * self.statistical_patterns.get('last_appearance', {}).get(n, len(self.results))\n",
    "                            for n in temp_nums)\n",
    "                # Thêm yếu tố ngẫu nhiên để tránh bị kẹt\n",
    "                if score > best_score or (score > best_score * 0.95 and random.random() < 0.3):\n",
    "                    best_score = score\n",
    "                    best_nums = temp_nums.copy()\n",
    "\n",
    "        logging.debug(f\"Optimized output (iteration {iteration}): {best_nums}\")\n",
    "        return best_nums[:6]\n",
    "\n",
    "    def train_models(self):\n",
    "        callbacks = [\n",
    "            EarlyStopping(monitor='val_loss', patience=8, restore_best_weights=True),\n",
    "            ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6),\n",
    "            ModelCheckpoint('best_model.h5', monitor='val_precision_at_k', save_best_only=True, mode='max'),\n",
    "            PrintTrainingMetrics()\n",
    "        ]\n",
    "\n",
    "        logging.info(\"Huấn luyện mô hình LSTM...\")\n",
    "        lstm_model = self.build_lstm_model()\n",
    "        y_train_bin = np.array([[1 if j+1 in draw else 0 for j in range(55)] for draw in self.y_train], dtype=np.float32)\n",
    "        y_test_bin = np.array([[1 if j+1 in draw else 0 for j in range(55)] for draw in self.y_test], dtype=np.float32)\n",
    "        lstm_model.fit(self.X_train, y_train_bin, validation_data=(self.X_test, y_test_bin),\n",
    "                       epochs=self.config['epochs'], batch_size=self.config['batch_size'], callbacks=callbacks, verbose=0)\n",
    "\n",
    "        logging.info(\"Huấn luyện mô hình GRU...\")\n",
    "        gru_model = self.build_gru_model()\n",
    "        gru_model.fit(self.X_train, y_train_bin, validation_data=(self.X_test, y_test_bin),\n",
    "                      epochs=self.config['epochs'], batch_size=self.config['batch_size'], callbacks=callbacks, verbose=0)\n",
    "\n",
    "        logging.info(\"Huấn luyện mô hình Transformer...\")\n",
    "        transformer_model = self.build_transformer_model()\n",
    "        transformer_model.fit(self.X_train, y_train_bin, validation_data=(self.X_test, y_test_bin),\n",
    "                              epochs=self.config['epochs'], batch_size=self.config['batch_size'], callbacks=callbacks, verbose=0)\n",
    "\n",
    "        self.train_rf_model()\n",
    "\n",
    "        return lstm_model, gru_model, transformer_model\n",
    "\n",
    "    def predict_ensemble(self, n_predictions=1):\n",
    "        logging.info(f\"Dự đoán {n_predictions} bộ số...\")\n",
    "        try:\n",
    "            lstm_model, gru_model, transformer_model = self.train_models()\n",
    "\n",
    "            lstm_probs = lstm_model.predict(self.last_sequence, verbose=0)[0]\n",
    "            gru_probs = gru_model.predict(self.last_sequence, verbose=0)[0]\n",
    "            transformer_probs = transformer_model.predict(self.last_sequence, verbose=0)[0]\n",
    "\n",
    "            last_features = self.last_sequence[0, :, 6:].reshape(1, -1)\n",
    "            rf_probs = self.rf_model.predict_proba(last_features)[0]\n",
    "\n",
    "            final_probs = (0.3 * lstm_probs + 0.3 * gru_probs + 0.3 * transformer_probs + 0.1 * rf_probs[:, 1]) / 4\n",
    "            final_probs = final_probs / final_probs.sum() if final_probs.sum() > 0 else np.ones(55) / 55\n",
    "\n",
    "            stat_probs = np.array([self.statistical_patterns.get('recent_frequencies', {}).get(i+1, 0) for i in range(55)])\n",
    "            final_probs = (0.7 * final_probs + 0.3 * stat_probs) / (0.7 + 0.3)\n",
    "\n",
    "            candidates = []\n",
    "            for i in range(n_predictions):\n",
    "                # Chọn ngẫu nhiên 10 số ban đầu từ top 20 để tăng tính đa dạng\n",
    "                top_20 = np.argsort(final_probs)[-20:][::-1] + 1\n",
    "                initial_nums = random.sample(top_20.tolist(), 10)\n",
    "                nums = self.optimize_numbers(initial_nums, final_probs, iteration=i)\n",
    "                candidates.append(nums)\n",
    "\n",
    "            df_predictions = pd.DataFrame(candidates, columns=[f'Số {i+1}' for i in range(6)])\n",
    "            df_predictions.to_csv('predictions.csv', index=False)\n",
    "            logging.info(\"Đã lưu dự đoán vào predictions.csv\")\n",
    "            return candidates\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Lỗi khi dự đoán: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        predictor = VietlottPredictor()\n",
    "        predictor.load_and_preprocess_data()\n",
    "        next_draw, next_date = predictor.get_next_draw(steps_ahead=2)\n",
    "        predictor.prepare_sequences()\n",
    "        predictions = predictor.predict_ensemble(n_predictions=2)\n",
    "        print(f\"\\nDự đoán cho kỳ quay {next_draw} (ngày {next_date.strftime('%Y-%m-%d')} - Hôm nay, 31/05/2025):\")\n",
    "        for i, pred in enumerate(predictions, 1):\n",
    "            print(f\"Bộ {i}: {pred}\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Lỗi chính: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fcdee85",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8b49b5f3",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af10ed6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb58b631",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
